{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f6157a",
   "metadata": {},
   "source": [
    "The original task arithmetic paper uses CLIP and builds classification heads with zero-shot training based on some templates.\n",
    "In our case, we have some special characteristics to keep in mind:\n",
    "- We are operating on medical, 3D, data.\n",
    "- Our objective is semantic labeling, not simple classification.\n",
    "\n",
    "To deal with this we have a couple of options to try:\n",
    "- Copy the same flow using CLIP trained on imagenet and slice the 3d images into multiple 2d.\n",
    "    - Since we need to do segmentation, we need to find a model that can perform segmentation and be finetuned\n",
    "    - Even better if we access separately the segmentation head and the encoder\n",
    "- Use 3d resnet pretrained on medicalnet by monai, perform a few short training loops with frozen encoder to train the segmentation head. \n",
    "- Use medsam/medsam2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.registry import get_dataset, split_train_into_train_val\n",
    "from src.modeling import Classifier, get_encoder\n",
    "from src.head import get_classification_head, build_classification_head\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from src.evaluation import evaluate_segmentation_performance\n",
    "import json\n",
    "from src.task_vector import TaskVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MM-WHS\"]\n",
    "domains = [\"CT\", \"MR\"]\n",
    "save_path = \"checkpoints/\"\n",
    "outputs_path = \"out/\"\n",
    "use_3d = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_3d = {(name, domain): get_dataset(dataset_name=name, domain=domain, location=f'data/{name}/', slice_2d=False, batch_size=1, num_workers=0)  for domain in domains for name in dataset_names}\n",
    "save_path = Path(save_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_metrics(name, new_metrics):\n",
    "    with open(outputs_path / \"metrics.json\", \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "    metrics[name] = new_metrics\n",
    "    with open(outputs_path / \"metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a17e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Finetuning loop\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset_names\u001b[49m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m domain \u001b[38;5;129;01min\u001b[39;00m domains:\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinetuning on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dataset in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m domain\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'dataset_names' is not defined"
     ]
    }
   ],
   "source": [
    "# finetuning loop\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        filename = save_path / filename\n",
    "        # Check if the finetuned checkpoint already exists\n",
    "        if filename.exists():\n",
    "            print(f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\")\n",
    "        dataset = get_dataset(dataset_name, domain, is_train=True, base_path = \"data/\", batch_size=1, num_workers=0, slice_2d=not use_3d)\n",
    "\n",
    "        model = dataset.get_model()\n",
    "\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline\", model_metrics)\n",
    "\n",
    "        tuned_model = model.finetune(\n",
    "            epochs=100,\n",
    "            save_path=filename,\n",
    "        )\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned\", model_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1df630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\")\n",
    "        baseline_checkpoint = save_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        finetuned_checkpoint = save_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322eb8af",
   "metadata": {},
   "source": [
    "## CHAOS \n",
    "CHAOS MRI has labels for multiple organs, but CHAOS CT has labels for only one organ (liver).\n",
    "For testing, we will use the liver label from CHAOS CT and the liver label from CHAOS MRI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af268f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_domain, target_domain in [(\"CT\", \"MR\"), (\"MR\", \"CT\")]:\n",
    "    task_vector: TaskVector = task_vectors[f\"CHAOS_{source_domain}\"]\n",
    "    chaos_target = get_dataset(\"CHAOS\", domain=target_domain, base_path=\"data/\", batch_size=1, num_workers=0, slice_2d=not use_3d, liver_only=True)\n",
    "    model = chaos_target.get_model()\n",
    "    model.load_task_vector(task_vector)\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(f\"CHAOS_{target_domain}_from_{source_domain}\", model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def63981",
   "metadata": {},
   "source": [
    "## MM-WHS\n",
    "Labels are the same in both domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_domain, target_domain in [(\"CT\", \"MR\"), (\"MR\", \"CT\")]:\n",
    "    task_vector: TaskVector = task_vectors[f\"MM-WHS_{source_domain}\"]\n",
    "    mmwhs_target = get_dataset(\"MM-WHS\", domain=target_domain, base_path=\"data/\", batch_size=1, num_workers=0, slice_2d=not use_3d)\n",
    "    model = mmwhs_target.get_model()\n",
    "    model.load_task_vector(task_vector)\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(f\"MM-WHS_{target_domain}_from_{source_domain}\", model_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
