{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f6157a",
   "metadata": {},
   "source": [
    "The original task arithmetic paper uses CLIP and builds classification heads with zero-shot training based on some templates.\n",
    "In our case, we have some special characteristics to keep in mind:\n",
    "- We are operating on medical, 3D, data.\n",
    "- Our objective is semantic labeling, not simple classification.\n",
    "\n",
    "To deal with this we have a couple of options to try:\n",
    "- Copy the same flow using CLIP trained on imagenet and slice the 3d images into multiple 2d.\n",
    "    - Since we need to do segmentation, we need to find a model that can perform segmentation and be finetuned\n",
    "    - Even better if we access separately the segmentation head and the encoder\n",
    "- Use 3d resnet pretrained on medicalnet by monai, perform a few short training loops with frozen encoder to train the segmentation head. \n",
    "- Use medsam/medsam2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment on Kaggle\n",
    "# !git clone https://github.com/parmigggiana/xai\n",
    "# %cd xai\n",
    "# !git pull\n",
    "# %pip install open-clip-torch napari[pyqt6,optional]==0.6.2a1 monai[einops,nibabel]>=1.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'typing_extensions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_dataset\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseDataset\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/src/datasets/registry.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m random_split\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchaos\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CHAOS\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/__init__.py:38\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mthreading\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     Any \u001b[38;5;28;01mas\u001b[39;00m _Any,\n\u001b[32m     26\u001b[39m     Callable \u001b[38;5;28;01mas\u001b[39;00m _Callable,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     Union \u001b[38;5;28;01mas\u001b[39;00m _Union,\n\u001b[32m     37\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParamSpec \u001b[38;5;28;01mas\u001b[39;00m _ParamSpec\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IntLikeType\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'typing_extensions'"
     ]
    }
   ],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector\n",
    "from src.utils import download_and_extract_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MMWHS\"]\n",
    "domains = [\"MR\"]#[\"CT\", \"MR\"]\n",
    "data_path = 'data/'\n",
    "checkpoint_path = \"checkpoints/\"\n",
    "outputs_path = \"outputs/\"\n",
    "use_3d = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "data_path = Path(data_path)\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = outputs_path / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "                metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning loop using the new hybrid approach\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    download_and_extract_dataset(dataset_name, data_path)\n",
    "\n",
    "    for domain in domains:\n",
    "\n",
    "        if domain == \"MR\":\n",
    "            def preprocess(x):\n",
    "                return {\n",
    "                    \"image\": torch.nn.functional.interpolate(\n",
    "                        x[\"image\"].float(), scale_factor=0.5\n",
    "                    ),\n",
    "                    \"label\": torch.nn.functional.interpolate(\n",
    "                        x[\"label\"].float(), scale_factor=0.5, mode=\"nearest\"\n",
    "                    ).long()  if x[\"label\"] is not None else None\n",
    "                }\n",
    "        elif domain == \"CT\":\n",
    "            def preprocess(x):\n",
    "                if x[\"image\"].shape[-1] > 256:\n",
    "                    return {\n",
    "                        \"image\": torch.nn.functional.interpolate(\n",
    "                            x[\"image\"].float(), scale_factor=0.125\n",
    "                        ),\n",
    "                        \"label\": torch.nn.functional.interpolate(\n",
    "                            x[\"label\"].float(), scale_factor=0.125, mode=\"nearest\"\n",
    "                        ).long() if x[\"label\"] is not None else None\n",
    "                    }\n",
    "                else:\n",
    "                    return x\n",
    "\n",
    "\n",
    "        filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        filename = checkpoint_path / filename\n",
    "        # Check if the finetuned checkpoint already exists\n",
    "        if filename.exists():\n",
    "            print(\n",
    "                f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images (hybrid approach)\"\n",
    "        )\n",
    "        dataset: BaseDataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            domain=domain,\n",
    "            preprocess=preprocess,\n",
    "            base_path=data_path,\n",
    "            batch_size=1,\n",
    "            num_workers=0,\n",
    "            slice_2d=not use_3d,\n",
    "        )\n",
    "\n",
    "        # Use the new hybrid model method\n",
    "        model = dataset.get_hybrid_model(\n",
    "            encoder_type=\"swin_unetr\",\n",
    "            use_semantic_head=False,\n",
    "        )\n",
    "\n",
    "        head_filename =  checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baselined.pth\"\n",
    "\n",
    "        # segmentation_head = model.semantic_head\n",
    "        # torch.save(segmentation_head, head_filename)\n",
    "\n",
    "        # Save the baseline model's state_dict before finetuning\n",
    "        baseline_filename =  checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baselined.pth\"\n",
    "        torch.save(model.encoder, baseline_filename)\n",
    "        print(f\"Processing {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images (hybrid approach)\")\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline_hybrid\",\n",
    "            model_metrics,\n",
    "        )\n",
    "\n",
    "        history = model.finetune(\n",
    "            epochs=5,\n",
    "            learning_rate=1e-4,\n",
    "            weight_decay=1e-5,\n",
    "        )\n",
    "        # Save the finetuned model's state_dict\n",
    "\n",
    "        torch.save(model.encoder, filename)\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned_hybrid\",\n",
    "            model_metrics,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1df630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\")\n",
    "        baseline_checkpoint = checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        finetuned_checkpoint = checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Vector Cross-Domain Evaluation (merged version, with nested loops for all configs)\n",
    "print(\"\\n🔄 Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for source_domain in domains:\n",
    "        for target_domain in domains:\n",
    "            if source_domain == target_domain:\n",
    "                continue\n",
    "            key = (dataset_name, source_domain, target_domain)\n",
    "            metrics_key = f\"{dataset_name}_{target_domain}_from_{source_domain}_hybrid\"\n",
    "            # Only add extra_kwarg 'liver_only' for CHAOS dataset\n",
    "            extra_kwargs = {}\n",
    "            if dataset_name == \"CHAOS\":\n",
    "                extra_kwargs[\"liver_only\"] = True\n",
    "            try:\n",
    "                task_vector_key = f\"{dataset_name}_{source_domain}\"\n",
    "                if task_vector_key in task_vectors:\n",
    "                    print(f\"\\n{dataset_name}: {source_domain} → {target_domain} adaptation\")\n",
    "                    # Load target domain dataset\n",
    "                    dataset_kwargs = dict(\n",
    "                        dataset_name=dataset_name,\n",
    "                        domain=target_domain,\n",
    "                        base_path=data_path,\n",
    "                        batch_size=1,\n",
    "                        num_workers=0,\n",
    "                        slice_2d=False,\n",
    "                    )\n",
    "                    dataset_kwargs.update(extra_kwargs)\n",
    "                    target_dataset = get_dataset(**dataset_kwargs)\n",
    "                    target_model = target_dataset.get_model()\n",
    "\n",
    "                    # Apply task vector from source domain\n",
    "                    source_task_vector = task_vectors[task_vector_key]\n",
    "                    target_model.load_task_vector(source_task_vector)\n",
    "\n",
    "                    # Evaluate cross-domain performance\n",
    "                    cross_domain_metrics = target_model.evaluate()\n",
    "                    update_metrics(metrics_key, cross_domain_metrics)\n",
    "\n",
    "                    print(f\"   ✅ {source_domain}→{target_domain}: Dice={cross_domain_metrics.get('dice', 0):.3f}\")\n",
    "                    print(f\"   📊 Hausdorff Distance: {cross_domain_metrics.get('hausdorff', 0):.3f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ {dataset_name} {source_domain}→{target_domain} error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display all metrics\n",
    "metrics_file = outputs_path / \"metrics.json\"\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        all_metrics = json.load(f)\n",
    "\n",
    "    print(\"\\n📊 COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline performance\n",
    "    print(\"\\n🏁 Baseline Performance (Hybrid Semantic-Guided):\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if 'baseline' in key and 'hybrid' in key:\n",
    "            dice = metrics.get('dice', 0)\n",
    "            hausdorff = metrics.get('hausdorff', 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Cross-domain adaptation results\n",
    "    print(\"\\n🔄 Cross-Domain Adaptation Results:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if 'from' in key and 'hybrid' in key:\n",
    "            dice = metrics.get('dice', 0)\n",
    "            hausdorff = metrics.get('hausdorff', 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "else:\n",
    "    print(\"No metrics file found. Run the experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee495495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the evaluation method with fixed tensor handling\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Testing evaluation method with hybrid model...\")\n",
    "\n",
    "try:\n",
    "    # Get a small dataset for testing\n",
    "    base_path = Path(\"data\")\n",
    "    test_dataset = get_dataset(\n",
    "        dataset_name='CHAOS',\n",
    "        base_path=base_path,\n",
    "        domain='CT',\n",
    "        slice_2d=False,  # 3D\n",
    "        batch_size=1,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset created: {type(test_dataset)}\")\n",
    "    print(f\"Number of classes: {test_dataset.num_classes}\")\n",
    "    print(f\"Class names: {test_dataset.classnames}\")\n",
    "\n",
    "    # Create hybrid model without semantic head to avoid transformer dependencies\n",
    "    hybrid_model = test_dataset.get_hybrid_model(encoder_type=\"swin_unetr\", use_semantic_head=False)\n",
    "\n",
    "    print(f\"Model created: {type(hybrid_model)}\")\n",
    "    print(f\"Model device: {next(hybrid_model.parameters()).device}\")\n",
    "\n",
    "    # Create a minimal test by getting one batch from the loader\n",
    "    test_loader = test_dataset.train_loader\n",
    "    print(f\"Dataset length: {len(test_dataset.train_dataset)}\")\n",
    "    print(f\"Loader batch size: {test_loader.batch_size}\")\n",
    "\n",
    "    batch = next(iter(test_loader))\n",
    "    print(f\"Batch image shape: {batch['image'].shape}\")\n",
    "    print(f\"Batch label shape: {batch.get('label', torch.empty(0)).shape}\")\n",
    "\n",
    "    # Test just the forward pass without evaluation metrics\n",
    "    with torch.no_grad():\n",
    "        images = batch['image']\n",
    "        print(f\"Images shape: {images.shape}\")\n",
    "        print(f\"Images min/max: {images.min():.3f}/{images.max():.3f}\")\n",
    "\n",
    "        # Test forward pass\n",
    "        output = hybrid_model(images)\n",
    "        print(f\"✓ Forward pass successful! Output shape: {output.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during test: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
