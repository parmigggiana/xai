{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f6157a",
   "metadata": {},
   "source": [
    "The original task arithmetic paper uses CLIP and builds classification heads with zero-shot training based on some templates.\n",
    "In our case, we have some special characteristics to keep in mind:\n",
    "- We are operating on medical, 3D, data.\n",
    "- Our objective is semantic labeling, not simple classification.\n",
    "\n",
    "To deal with this we have a couple of options to try:\n",
    "- Copy the same flow using CLIP trained on imagenet and slice the 3d images into multiple 2d.\n",
    "    - Since we need to do segmentation, we need to find a model that can perform segmentation and be finetuned\n",
    "    - Even better if we access separately the segmentation head and the encoder\n",
    "- Use 3d resnet pretrained on medicalnet by monai, perform a few short training loops with frozen encoder to train the segmentation head. \n",
    "- Use medsam/medsam2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bb3b4",
   "metadata": {},
   "source": [
    "In Kaggle, add the following to the dependencies:\n",
    "```\n",
    "pip install 'torch>=1.12.1'\n",
    "torchvision\n",
    "numpy\n",
    "pydicom\n",
    "PILlow\n",
    "matplotlib\n",
    "transformers>=4.20.0\n",
    "git+https://github.com/bowang-lab/MedSAM2.git\n",
    "```\n",
    "Also remember to enable file persistence and internet access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment on Kaggle\n",
    "# !git clone https://github.com/parmigggiana/xai /kaggle/working/xai\n",
    "# %cd xai\n",
    "# !git pull\n",
    "# %pip install 'napari[pyqt6,optional]==0.6.2a1' 'monai[einops,nibabel]>=1.1.0' open-clip-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment on Colab\n",
    "# !git clone https://github.com/parmigggiana/xai /content/xai\n",
    "# %cd /content/xai\n",
    "# !git fetch\n",
    "# !git reset --hard origin/main\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector\n",
    "from src.utils import download_and_extract_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MMWHS\"]\n",
    "domains = [\"MR\", \"CT\"]\n",
    "data_path = \"data/\"\n",
    "checkpoint_path = \"checkpoints/\"\n",
    "outputs_path = \"outputs/\"\n",
    "use_3d = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "data_path = Path(data_path)\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = outputs_path / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "\n",
    "def get_preprocessing(domain):\n",
    "    # if domain == \"MR\":\n",
    "    #         def preprocess(x):\n",
    "    #             return {\n",
    "    #                 \"image\": torch.nn.functional.interpolate(\n",
    "    #                     x[\"image\"].float(), scale_factor=0.5\n",
    "    #                 ),\n",
    "    #                 \"label\": torch.nn.functional.interpolate(\n",
    "    #                     x[\"label\"].float(), scale_factor=0.5, mode=\"nearest\"\n",
    "    #                 ).long()  if x[\"label\"] is not None else None\n",
    "    #             }\n",
    "    # elif domain == \"CT\":\n",
    "    #     def preprocess(x):\n",
    "    #         if x[\"image\"].shape[-1] > 256:\n",
    "    #             return {\n",
    "    #                 \"image\": torch.nn.functional.interpolate(\n",
    "    #                     x[\"image\"].float(), scale_factor=0.125\n",
    "    #                 ),\n",
    "    #                 \"label\": torch.nn.functional.interpolate(\n",
    "    #                     x[\"label\"].float(), scale_factor=0.125, mode=\"nearest\"\n",
    "    #                 ).long() if x[\"label\"] is not None else None\n",
    "    #             }\n",
    "    #         else:\n",
    "    #             return x\n",
    "\n",
    "    def preprocess(x):\n",
    "        # Only scale down to (96, 128, 128) if larger\n",
    "        target_shape = (96, 128, 128)\n",
    "        img = x[\"image\"].float()\n",
    "        lbl = x[\"label\"].float() if x[\"label\"] is not None else None\n",
    "\n",
    "        if img.shape[-3:] != target_shape:\n",
    "            img = torch.nn.functional.interpolate(\n",
    "                img.unsqueeze(0),\n",
    "                size=target_shape,\n",
    "                mode=\"trilinear\",\n",
    "                align_corners=False,\n",
    "            ).squeeze(0)\n",
    "            if lbl is not None:\n",
    "                lbl = (\n",
    "                    torch.nn.functional.interpolate(\n",
    "                        lbl.unsqueeze(0), size=target_shape, mode=\"nearest\"\n",
    "                    )\n",
    "                    .squeeze(0)\n",
    "                    .long()\n",
    "                )\n",
    "        else:\n",
    "            if lbl is not None:\n",
    "                lbl = lbl.long()\n",
    "\n",
    "        return {\"image\": img, \"label\": lbl}\n",
    "\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning loop using the new hybrid approach\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    download_and_extract_dataset(dataset_name, data_path)\n",
    "\n",
    "    for domain in domains:\n",
    "\n",
    "        preprocess = get_preprocessing(domain)\n",
    "\n",
    "        filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        filename = checkpoint_path / filename\n",
    "        # Check if the finetuned checkpoint already exists\n",
    "        if filename.exists():\n",
    "            print(\n",
    "                f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images (hybrid approach)\"\n",
    "        )\n",
    "        dataset: BaseDataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            domain=domain,\n",
    "            preprocess=preprocess,\n",
    "            base_path=data_path,\n",
    "            batch_size=1,\n",
    "            num_workers=1,\n",
    "            slice_2d=not use_3d,\n",
    "        )\n",
    "\n",
    "        # Use the new hybrid model method\n",
    "        model = dataset.get_hybrid_model(\n",
    "            encoder_type=\"swin_unetr\",\n",
    "            use_semantic_head=False,\n",
    "        )\n",
    "\n",
    "        head_filename = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        )\n",
    "\n",
    "        # segmentation_head = model.semantic_head\n",
    "        # torch.save(segmentation_head, head_filename)\n",
    "\n",
    "        # Save the baseline model's state_dict before finetuning\n",
    "        baseline_filename = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        )\n",
    "        torch.save(model.encoder, baseline_filename)\n",
    "        print(\n",
    "            f\"Processing {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images (hybrid approach)\"\n",
    "        )\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline_hybrid\",\n",
    "            model_metrics,\n",
    "        )\n",
    "\n",
    "        history = model.finetune(\n",
    "            epochs=15,\n",
    "            learning_rate=5e-4,\n",
    "            weight_decay=1e-5,\n",
    "        )\n",
    "        # Save the finetuned model's state_dict\n",
    "\n",
    "        torch.save(model.encoder, filename)\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned_hybrid\",\n",
    "            model_metrics,\n",
    "        )\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1df630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.networks.nets.swin_unetr import SwinTransformer\n",
    "from monai.networks.blocks.patchembedding import PatchEmbed\n",
    "from torch.nn.modules.conv import Conv3d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.container import ModuleList\n",
    "from monai.networks.nets.swin_unetr import BasicLayer\n",
    "from monai.networks.nets.swin_unetr import SwinTransformerBlock\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "from monai.networks.nets.swin_unetr import WindowAttention\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch.nn.modules.activation import Softmax\n",
    "from torch.nn.modules.linear import Identity\n",
    "from monai.networks.blocks.mlp import MLPBlock\n",
    "from torch.nn.modules.activation import GELU\n",
    "from monai.networks.nets.swin_unetr import PatchMerging\n",
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock\n",
    "from monai.networks.blocks.dynunet_block import UnetResBlock\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "from torch.nn.modules.activation import LeakyReLU\n",
    "from torch.nn.modules.instancenorm import InstanceNorm3d\n",
    "from monai.networks.blocks.unetr_block import UnetrUpBlock\n",
    "from torch.nn.modules.conv import ConvTranspose3d\n",
    "from monai.networks.blocks.dynunet_block import UnetOutBlock\n",
    "\n",
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(\n",
    "            f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\"\n",
    "        )\n",
    "        baseline_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        )\n",
    "        finetuned_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        )\n",
    "        with torch.serialization.safe_globals(\n",
    "            [\n",
    "                SwinUNETR,\n",
    "                SwinTransformer,\n",
    "                PatchEmbed,\n",
    "                Conv3d,\n",
    "                Dropout,\n",
    "                ModuleList,\n",
    "                BasicLayer,\n",
    "                SwinTransformerBlock,\n",
    "                LayerNorm,\n",
    "                WindowAttention,\n",
    "                Linear,\n",
    "                Softmax,\n",
    "                Identity,\n",
    "                MLPBlock,\n",
    "                GELU,\n",
    "                PatchMerging,\n",
    "                UnetrBasicBlock,\n",
    "                UnetResBlock,\n",
    "                Convolution,\n",
    "                LeakyReLU,\n",
    "                InstanceNorm3d,\n",
    "                UnetrUpBlock,\n",
    "                ConvTranspose3d,\n",
    "                UnetOutBlock,\n",
    "            ]\n",
    "        ):\n",
    "            task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Vector Cross-Domain Evaluation (merged version, with nested loops for all configs)\n",
    "print(\"\\nüîÑ Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for source_domain in domains:\n",
    "        for target_domain in domains:\n",
    "            if source_domain == target_domain:\n",
    "                continue\n",
    "            key = (dataset_name, source_domain, target_domain)\n",
    "            metrics_key = f\"{dataset_name}_{target_domain}_from_{source_domain}_hybrid\"\n",
    "            # Only add extra_kwarg 'liver_only' for CHAOS dataset\n",
    "            extra_kwargs = {}\n",
    "            if dataset_name == \"CHAOS\":\n",
    "                extra_kwargs[\"liver_only\"] = True\n",
    "            try:\n",
    "                task_vector_key = f\"{dataset_name}_{source_domain}\"\n",
    "                if task_vector_key in task_vectors:\n",
    "                    print(\n",
    "                        f\"\\n{dataset_name}: {source_domain} ‚Üí {target_domain} adaptation\"\n",
    "                    )\n",
    "                    # Load target domain dataset\n",
    "                    dataset_kwargs = dict(\n",
    "                        dataset_name=dataset_name,\n",
    "                        domain=target_domain,\n",
    "                        base_path=data_path,\n",
    "                        batch_size=1,\n",
    "                        num_workers=1,\n",
    "                        slice_2d=False,\n",
    "                    )\n",
    "                    dataset_kwargs.update(extra_kwargs)\n",
    "                    target_dataset = get_dataset(**dataset_kwargs)\n",
    "                    target_model = target_dataset.get_hybrid_model(\n",
    "                        encoder_type=\"swin_unetr\",\n",
    "                        use_semantic_head=False,\n",
    "                    )\n",
    "\n",
    "                    # Apply task vector from source domain\n",
    "                    source_task_vector = task_vectors[task_vector_key]\n",
    "                    target_model.load_task_vector(source_task_vector)\n",
    "\n",
    "                    # Evaluate cross-domain performance\n",
    "                    cross_domain_metrics = target_model.evaluate()\n",
    "                    update_metrics(metrics_key, cross_domain_metrics)\n",
    "\n",
    "                    print(\n",
    "                        f\"   ‚úÖ {source_domain}‚Üí{target_domain}: Dice={cross_domain_metrics.get('dice', 0):.3f}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"   üìä Hausdorff Distance: {cross_domain_metrics.get('hausdorff', 0):.3f}\"\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    f\"   ‚ùå {dataset_name} {source_domain}‚Üí{target_domain} error: {e}\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display all metrics\n",
    "metrics_file = outputs_path / \"metrics.json\"\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, \"r\") as f:\n",
    "        all_metrics = json.load(f)\n",
    "\n",
    "    print(\"\\nüìä COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline performance\n",
    "    print(\"\\nüèÅ Baseline Performance (Hybrid Semantic-Guided):\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"baseline\" in key and \"hybrid\" in key:\n",
    "            dice = metrics.get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Cross-domain adaptation results\n",
    "    print(\"\\nüîÑ Cross-Domain Adaptation Results:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"from\" in key and \"hybrid\" in key:\n",
    "            dice = metrics.get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "else:\n",
    "    print(\"No metrics file found. Run the experiments first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
