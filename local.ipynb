{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0bb3b4",
   "metadata": {},
   "source": [
    "In Kaggle, add the following to the dependencies:\n",
    "```\n",
    "pip install torch\n",
    "pip install numpy\n",
    "pip install pydicom\n",
    "pip install PILlow\n",
    "pip install matplotlib\n",
    "```\n",
    "Enable file persistence and internet access.\n",
    "Remember that you can run the whole notebook and close the runtime without wasting resources by going to File > Save Version > Save & Run All (Double check that GPU is selected in the advanced settings).\n",
    "Later, by going to 'File' > 'Version history' you can view the full logs and download the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Kaggle\n",
    "import os\n",
    "\n",
    "IN_KAGGLE = False\n",
    "if os.environ.get(\"KAGGLE_URL_BASE\", \"\"):\n",
    "    IN_KAGGLE = True\n",
    "    !git clone https://github.com/parmigggiana/xai /kaggle/working/xai\n",
    "    %cd xai\n",
    "    !git fetch\n",
    "    !git reset --hard origin/main\n",
    "    %pip install 'monai[einops,itk]>=1.5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "IN_COLAB = False\n",
    "if not IN_KAGGLE:\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import drive\n",
    "\n",
    "        IN_COLAB = True\n",
    "        import os\n",
    "\n",
    "        drive.mount(\"/content/drive\")\n",
    "        os.makedirs(\"/content/drive/MyDrive/xai\", exist_ok=True)\n",
    "        !git clone https://github.com/parmigggiana/xai /content/xai\n",
    "        %cd /content/xai\n",
    "        !git fetch\n",
    "        !git reset --hard origin/main\n",
    "        %pip install -r requirements.txt\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector\n",
    "from src.utils import download_and_extract_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MMWHS\"]\n",
    "domains = [\"MR\", \"CT\"]\n",
    "data_path = \"data/\"\n",
    "checkpoint_path = \"checkpoints/\"\n",
    "outputs_path = \"outputs/\"\n",
    "use_3d = True\n",
    "training_epochs = {\n",
    "    (\"CHAOS\", \"MR\"): 30,\n",
    "    (\"CHAOS\", \"CT\"): 10,\n",
    "    (\"MMWHS\", \"MR\"): 30,\n",
    "    (\"MMWHS\", \"CT\"): 20,\n",
    "}\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "data_path = Path(data_path)\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai import transforms\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = outputs_path / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "\n",
    "def debug_metadata(data):\n",
    "    \"\"\"Debug transform to print metadata information\"\"\"\n",
    "    print(f\"üîç DEBUG - Data type: {type(data)}\")\n",
    "    if hasattr(data, \"meta\"):\n",
    "        print(\n",
    "            f\"üîç DEBUG - Metadata keys: {list(data.meta.keys()) if data.meta else 'No meta'}\"\n",
    "        )\n",
    "        print(f\"üîç DEBUG - Full metadata: {data.meta}\")\n",
    "    if hasattr(data, \"shape\"):\n",
    "        print(f\"üîç DEBUG - Shape: {data.shape}\")\n",
    "    if hasattr(data, \"dtype\"):\n",
    "        print(f\"üîç DEBUG - Dtype: {data.dtype}\")\n",
    "    print(\"üîç DEBUG - \" + \"=\" * 50)\n",
    "    return data\n",
    "\n",
    "class MetadataAwareTransform:\n",
    "    \"\"\"Wrapper to make transforms work with (data, metadata) tuples\"\"\"\n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __call__(self, data_tuple):\n",
    "        if isinstance(data_tuple, tuple) and len(data_tuple) == 2:\n",
    "            data, metadata = data_tuple\n",
    "            try:\n",
    "                transformed_data = self.transform(data)\n",
    "                return transformed_data, metadata\n",
    "            except Exception as e:\n",
    "                print(f\"Error in transform {self.transform}: {e}\")\n",
    "                # Return original data if transform fails\n",
    "                return data, metadata\n",
    "        else:\n",
    "            # Fallback for non-tuple input\n",
    "            return self.transform(data_tuple)\n",
    "\n",
    "\n",
    "class MetadataCompose:\n",
    "    \"\"\"Custom Compose that handles (data, metadata) tuples properly\"\"\"\n",
    "\n",
    "    def __init__(self, transforms_list):\n",
    "        self.transforms_list = transforms_list\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Apply transforms sequentially, handling both tuple and separate arguments\"\"\"\n",
    "        # Handle case where apply_transform unpacks tuple as separate arguments\n",
    "        if len(args) == 2 and not kwargs:\n",
    "            data, metadata = args\n",
    "            data_tuple = (data, metadata)\n",
    "        elif len(args) == 1:\n",
    "            data_tuple = args[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected arguments: args={args}, kwargs={kwargs}\")\n",
    "\n",
    "        if isinstance(data_tuple, tuple) and len(data_tuple) == 2:\n",
    "            data, metadata = data_tuple\n",
    "\n",
    "            # Apply each transform sequentially\n",
    "            for transform in self.transforms_list:\n",
    "                if isinstance(transform, MetadataAwareTransform):\n",
    "                    data, metadata = transform((data, metadata))\n",
    "                else:\n",
    "                    # For regular transforms, just transform the data\n",
    "                    data = transform(data)\n",
    "\n",
    "            return data, metadata\n",
    "        else:\n",
    "            # Fallback for non-tuple input - apply transforms normally\n",
    "            result = data_tuple\n",
    "            for transform in self.transforms_list:\n",
    "                if isinstance(transform, MetadataAwareTransform):\n",
    "                    result = transform.transform(result)\n",
    "                else:\n",
    "                    result = transform(result)\n",
    "            return result\n",
    "\n",
    "    def set_random_state(self, seed=None):\n",
    "        \"\"\"Set random state for randomizable transforms\"\"\"\n",
    "        for transform in self.transforms_list:\n",
    "            if hasattr(transform, 'set_random_state'):\n",
    "                transform.set_random_state(seed=seed)\n",
    "            elif hasattr(transform, 'transform') and hasattr(transform.transform, 'set_random_state'):\n",
    "                transform.transform.set_random_state(seed=seed)\n",
    "\n",
    "\n",
    "def get_preprocessing(domain, is_training=True):\n",
    "    \"\"\"\n",
    "    Get comprehensive preprocessing pipeline for volumetric medical data.\n",
    "\n",
    "    Returns separate transforms for images and segmentations to work with ImageDataset.\n",
    "    Handles different file formats based on dataset:\n",
    "    - CHAOS: DICOM images (directories), PNG labels (directories)\n",
    "    - MMWHS: NIfTI images and labels\n",
    "\n",
    "    Note: Spatial transforms (Spacing, Resize) are handled separately to ensure\n",
    "    synchronized dimensions between images and labels.\n",
    "    \"\"\"\n",
    "    if use_3d:\n",
    "\n",
    "        # Image-specific transforms (applied to image files)\n",
    "        # Note: No spatial transforms here - they're handled synchronously\n",
    "        image_transforms = [\n",
    "            # transforms.Lambda(\n",
    "            #     lambda x: print(f\"image shape: {x.shape}\") or x\n",
    "            # ),  # Debug transform for images\n",
    "            transforms.EnsureChannelFirst(\n",
    "                channel_dim=\"no_channel\"\n",
    "            ),\n",
    "            transforms.Orientation(axcodes=\"RAS\"),\n",
    "        ]\n",
    "\n",
    "        # Domain-specific intensity normalization for images\n",
    "        if domain == \"CT\":\n",
    "            image_transforms.append(\n",
    "                transforms.ScaleIntensityRange(\n",
    "                    a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True\n",
    "                ),\n",
    "            )\n",
    "        else:  # MR\n",
    "            image_transforms.append(\n",
    "                transforms.NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "            )\n",
    "\n",
    "        # Training-specific augmentations for images only\n",
    "        if is_training:\n",
    "            # Image-only augmentations (safe for ImageDataset)\n",
    "            augmentation_transforms = [\n",
    "                transforms.RandGaussianNoise(prob=0.2, std=0.05),\n",
    "                transforms.RandAdjustContrast(prob=0.2, gamma=(0.9, 1.1)),\n",
    "            ]\n",
    "            image_transforms.extend(augmentation_transforms)\n",
    "\n",
    "        # Final conversion to tensor for images\n",
    "        image_transforms.extend(\n",
    "            [\n",
    "                transforms.Resize(spatial_size=64, size_mode=\"longest\", mode=\"area\"),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.EnsureType(dtype=torch.float32),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Segmentation-specific transforms (applied to segmentation files)\n",
    "        # Note: No spatial transforms here - they're handled synchronously\n",
    "        seg_transforms = [\n",
    "            # transforms.Lambda(\n",
    "            #     lambda x: print(f\"seg shape: {x.shape}\") or x\n",
    "            # ),  # Debug transform for segmentations\n",
    "            transforms.EnsureChannelFirst(\n",
    "                channel_dim=\"no_channel\"\n",
    "            ),  # Ensure channel-first format\n",
    "            transforms.Orientation(axcodes=\"RAS\"),  # Standardize spatial orientation\n",
    "            transforms.Resize(spatial_size=64, size_mode=\"longest\", mode=\"area\"),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.EnsureType(dtype=torch.float32),\n",
    "        ]\n",
    "\n",
    "        # NOTE: Claude's suggestion, probably there's better approaches here than creating custom classes but I need to read the MONAI docs better\n",
    "        # Wrap transforms to handle metadata properly\n",
    "        metadata_aware_image_transforms = [MetadataAwareTransform(t) for t in image_transforms]\n",
    "        metadata_aware_seg_transforms = [MetadataAwareTransform(t) for t in seg_transforms]\n",
    "\n",
    "        # Create separate transform pipelines that handle metadata\n",
    "        image_transform = MetadataCompose(metadata_aware_image_transforms)\n",
    "        seg_transform = MetadataCompose(metadata_aware_seg_transforms)\n",
    "\n",
    "        return image_transform, seg_transform\n",
    "\n",
    "    else:\n",
    "        # 2D preprocessing (if needed)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning loop\n",
    "\n",
    "for (dataset_name, domain), epochs in training_epochs.items():\n",
    "    download_and_extract_dataset(dataset_name, data_path)\n",
    "\n",
    "    # Get separate transforms for images and segmentations\n",
    "    image_transform, seg_transform = get_preprocessing(\n",
    "        domain, is_training=True\n",
    "    )\n",
    "\n",
    "    filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "    filename = checkpoint_path / filename\n",
    "    # Check if the finetuned checkpoint already exists\n",
    "    if filename.exists():\n",
    "        print(\n",
    "            f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    print(\n",
    "        f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images \"\n",
    "    )\n",
    "    dataset: BaseDataset = get_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        domain=domain,\n",
    "        transform=image_transform,  # Use transform instead of preprocess\n",
    "        seg_transform=seg_transform,  # Pass seg_transform too\n",
    "        base_path=data_path,\n",
    "        batch_size=1,\n",
    "        num_workers=0,\n",
    "        slice_2d=not use_3d,\n",
    "    )\n",
    "\n",
    "    model = dataset.get_model(\n",
    "        encoder_type=\"swin_unetr\",\n",
    "    )\n",
    "\n",
    "    # Save the baseline model's state_dict before finetuning\n",
    "    baseline_filename = (\n",
    "        checkpoint_path\n",
    "        / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "    )\n",
    "    torch.save(model.encoder, baseline_filename)\n",
    "    print(\n",
    "        f\"Processing {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images\"\n",
    "    )\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline\",\n",
    "        model_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the segmentation head\n",
    "    # For the proposal of the paper this part should not be done like this!\n",
    "    # This requires data - the original task arithmetic paper builds classification heads using no data, only templates\n",
    "    # if we have time this point should be addressed, otherwise at least mention that the technical problem\n",
    "    # requires more developement time and the proof of concept should still be somewhat solid.\n",
    "    model.freeze_body()\n",
    "    model.finetune(\n",
    "        epochs=epochs, learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    # Save the head\n",
    "    torch.save(\n",
    "        model.head,\n",
    "        checkpoint_path\n",
    "        / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_head.pth\",\n",
    "    )\n",
    "\n",
    "    metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_head\",\n",
    "        metrics,\n",
    "    )\n",
    "\n",
    "    # Finetune the encoder-decoder\n",
    "    model.unfreeze()\n",
    "    model.freeze_head()\n",
    "    history = model.finetune(\n",
    "        epochs=epochs,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "    # Save the finetuned model's state_dict\n",
    "\n",
    "    torch.save(model.encoder, filename)\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned\",\n",
    "        model_metrics,\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.networks.nets.swin_unetr import SwinTransformer\n",
    "from monai.networks.blocks.patchembedding import PatchEmbed\n",
    "from torch.nn.modules.conv import Conv3d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.container import ModuleList\n",
    "from monai.networks.nets.swin_unetr import BasicLayer\n",
    "from monai.networks.nets.swin_unetr import SwinTransformerBlock\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "from monai.networks.nets.swin_unetr import WindowAttention\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch.nn.modules.activation import Softmax\n",
    "from torch.nn.modules.linear import Identity\n",
    "from monai.networks.blocks.mlp import MLPBlock\n",
    "from torch.nn.modules.activation import GELU\n",
    "from monai.networks.nets.swin_unetr import PatchMerging\n",
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock\n",
    "from monai.networks.blocks.dynunet_block import UnetResBlock\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "from torch.nn.modules.activation import LeakyReLU\n",
    "from torch.nn.modules.instancenorm import InstanceNorm3d\n",
    "from monai.networks.blocks.unetr_block import UnetrUpBlock\n",
    "from torch.nn.modules.conv import ConvTranspose3d\n",
    "from monai.networks.blocks.dynunet_block import UnetOutBlock\n",
    "\n",
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(\n",
    "            f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\"\n",
    "        )\n",
    "        baseline_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        )\n",
    "        finetuned_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        )\n",
    "        with torch.serialization.safe_globals(\n",
    "            [\n",
    "                SwinUNETR,\n",
    "                SwinTransformer,\n",
    "                PatchEmbed,\n",
    "                Conv3d,\n",
    "                Dropout,\n",
    "                ModuleList,\n",
    "                BasicLayer,\n",
    "                SwinTransformerBlock,\n",
    "                LayerNorm,\n",
    "                WindowAttention,\n",
    "                Linear,\n",
    "                Softmax,\n",
    "                Identity,\n",
    "                MLPBlock,\n",
    "                GELU,\n",
    "                PatchMerging,\n",
    "                UnetrBasicBlock,\n",
    "                UnetResBlock,\n",
    "                Convolution,\n",
    "                LeakyReLU,\n",
    "                InstanceNorm3d,\n",
    "                UnetrUpBlock,\n",
    "                ConvTranspose3d,\n",
    "                UnetOutBlock,\n",
    "            ]\n",
    "        ):\n",
    "            task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "            # Remove keys associated with the .out layer from the task vector\n",
    "            out_layer_keys = [k for k in task_vector.keys() if \"out.\" in k]\n",
    "            for k in out_layer_keys:\n",
    "                del task_vector[k]\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build composite task vectors using arithmetic\n",
    "composite_task_vectors = {\n",
    "    \"MMWHS_CT\": task_vectors[\"MMWHS_MR\"]\n",
    "    + task_vectors[\"CHAOS_CT\"]\n",
    "    - task_vectors[\"CHAOS_MR\"],\n",
    "    \"MMWHS_MR\": task_vectors[\"MMWHS_CT\"]\n",
    "    + task_vectors[\"CHAOS_MR\"]\n",
    "    - task_vectors[\"CHAOS_CT\"],\n",
    "    \"CHAOS_CT\": task_vectors[\"CHAOS_MR\"]\n",
    "    + task_vectors[\"MMWHS_CT\"]\n",
    "    - task_vectors[\"MMWHS_MR\"],\n",
    "    \"CHAOS_MR\": task_vectors[\"CHAOS_CT\"]\n",
    "    + task_vectors[\"MMWHS_MR\"]\n",
    "    - task_vectors[\"MMWHS_CT\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ Task Vector Cross-Domain Adaptation Experiments\n",
    "print(\"üîÑ Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for target_domain in domains:\n",
    "        print(f\"\\n{dataset_name}: {target_domain} adaptation\")\n",
    "\n",
    "        # Get separate transforms for target domain, passing dataset_name for correct readers\n",
    "        image_transform, seg_transform = get_preprocessing(\n",
    "            target_domain, is_training=False\n",
    "        )\n",
    "        # image_transform = None\n",
    "        # seg_transform = None\n",
    "\n",
    "        dataset_kwargs = {\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"base_path\": data_path,\n",
    "            \"domain\": target_domain,\n",
    "            \"transform\": image_transform,  # Use transform instead of preprocess\n",
    "            \"seg_transform\": seg_transform,  # Pass seg_transform too\n",
    "            \"batch_size\": 1,\n",
    "            \"num_workers\": 0,\n",
    "        }\n",
    "        extra_kwargs = {}\n",
    "        if dataset_name == \"CHAOS\":\n",
    "            extra_kwargs[\"liver_only\"] = True\n",
    "\n",
    "        # try:\n",
    "        target_dataset = get_dataset(**dataset_kwargs, **extra_kwargs)\n",
    "\n",
    "        composite_key = f\"{dataset_name}_{target_domain}\"\n",
    "        if composite_key in composite_task_vectors:\n",
    "            composite_task_vector = composite_task_vectors[composite_key]\n",
    "\n",
    "            target_model = target_dataset.get_model()\n",
    "            target_model.load_task_vector(composite_task_vector)\n",
    "            # target_model.setup_for_dataset(target_dataset)\n",
    "\n",
    "            metrics = target_model.evaluate()\n",
    "            update_metrics(f\"{composite_key}_adaptation\", metrics)\n",
    "            print(\n",
    "                f\"   ‚úÖ {composite_key}: Dice={metrics.get('train', {}).get('dice', 0):.3f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è No composite task vector found for {composite_key}\")\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(f\"   ‚ùå {dataset_name} {target_domain}: {str(e)[:100]}...\")\n",
    "        #     import traceback\n",
    "        #     traceback.print_exc()\n",
    "        #     # continue\n",
    "        #     break\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display all metrics\n",
    "metrics_file = outputs_path / \"metrics.json\"\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, \"r\") as f:\n",
    "        all_metrics = json.load(f)\n",
    "\n",
    "    print(\"\\nüìä COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline performance\n",
    "    print(\"\\nüèÅ Baseline Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"baseline\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # After Head-training performance\n",
    "    print(\"\\nüèãÔ∏è‚Äç‚ôÇÔ∏è After Head-Training Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"head\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Finetuned performance\n",
    "    print(\"\\nüèÜ Finetuned Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"finetuned\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Cross-domain adaptation results\n",
    "    print(\"\\nüîÑ Cross-Domain Adaptation Results:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"adaptation\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "else:\n",
    "    print(\"No metrics file found. Run the experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import shutil\n",
    "\n",
    "    # Copy checkpoints.zip to Google Drive\n",
    "    !zip -r /content/checkpoints.zip /content/xai/checkpoints\n",
    "    shutil.copy(\n",
    "        \"/content/checkpoints.zip\", \"/content/drive/MyDrive/xai/checkpoints.zip\"\n",
    "    )\n",
    "\n",
    "    # Copy metrics.json to Google Drive\n",
    "    shutil.copy(\n",
    "        \"/content/xai/outputs/metrics.json\", \"/content/drive/MyDrive/xai/metrics.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE:\n",
    "    !zip -r /kaggle/working/checkpoints.zip /kaggle/working/xai/checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
