{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f6157a",
   "metadata": {},
   "source": [
    "The original task arithmetic paper uses CLIP and builds classification heads with zero-shot training based on some templates.\n",
    "In our case, we have some special characteristics to keep in mind:\n",
    "- We are operating on medical, 3D, data.\n",
    "- Our objective is semantic labeling, not simple classification.\n",
    "\n",
    "To deal with this we have a couple of options to try:\n",
    "- Copy the same flow using CLIP trained on imagenet and slice the 3d images into multiple 2d.\n",
    "    - Since we need to do segmentation, we need to find a model that can perform segmentation and be finetuned\n",
    "    - Even better if we access separately the segmentation head and the encoder\n",
    "- Use 3d resnet pretrained on medicalnet by monai, perform a few short training loops with frozen encoder to train the segmentation head. \n",
    "- Use medsam/medsam2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MMWHS\"]\n",
    "domains = [\"MR\"]#[\"CT\", \"MR\"]\n",
    "data_path = 'data/'\n",
    "checkpoint_path = \"checkpoints/\"\n",
    "outputs_path = \"outputs/\"\n",
    "use_3d = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "data_path = Path(data_path)\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = outputs_path / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "                metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning on CHAOS dataset in MR domain with 3d images (hybrid approach)\n",
      "2025-07-10 15:05:58,539 - INFO - Expected md5 is None, skip md5 check for file data/ssl_pretrained_weights.pth.\n",
      "2025-07-10 15:05:58,539 - INFO - File exists: data/ssl_pretrained_weights.pth, skipped downloading.\n",
      "Error loading SwinViT weights: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/home/basilef/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.metrics.utils get_mask_edges:always_return_as_numpy: Argument `always_return_as_numpy` has been deprecated since version 1.5.0. It will be removed in version 1.7.0. The option is removed and the return type will always be equal to the input type.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "/home/basilef/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/monai/metrics/utils.py:327: UserWarning: the ground truth of class 0 is all 0, this may result in nan/inf distance.\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [09:20<00:00, 28.05s/it]\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:172\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    169\u001b[39m clone = copy.copy(elem)\n\u001b[32m    170\u001b[39m clone.update(\n\u001b[32m    171\u001b[39m     {\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m         key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[32m    176\u001b[39m     }\n\u001b[32m    177\u001b[39m )\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clone\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:240\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    235\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    236\u001b[39m                 collate(samples, collate_fn_map=collate_fn_map)\n\u001b[32m    237\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    238\u001b[39m             ]\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format.format(elem_type))\n",
      "\u001b[31mTypeError\u001b[39m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     38\u001b[39m baseline_filename =  checkpoint_path / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m3d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39muse_3d\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m2d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_baselined.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     39\u001b[39m torch.save(model.encoder, baseline_filename)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m model_metrics = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m update_metrics(\n\u001b[32m     42\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m3d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39muse_3d\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m2d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_baseline_hybrid\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m     model_metrics,\n\u001b[32m     44\u001b[39m )\n\u001b[32m     46\u001b[39m model.finetune(\n\u001b[32m     47\u001b[39m     epochs=\u001b[32m5\u001b[39m,\n\u001b[32m     48\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/src/semantic_segmentation.py:575\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m loss_function = DiceCELoss(\n\u001b[32m    563\u001b[39m     include_background=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    564\u001b[39m     to_onehot_y=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    568\u001b[39m     smooth_dr=\u001b[32m1e-6\u001b[39m,\n\u001b[32m    569\u001b[39m )\n\u001b[32m    571\u001b[39m \u001b[38;5;66;03m# Setup optimizer\u001b[39;00m\n\u001b[32m    572\u001b[39m optimizer = optim.AdamW(\n\u001b[32m    573\u001b[39m     \u001b[38;5;28mself\u001b[39m.parameters(),\n\u001b[32m    574\u001b[39m     lr=learning_rate,\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     weight_decay=weight_decay\n\u001b[32m    576\u001b[39m )\n\u001b[32m    578\u001b[39m \u001b[38;5;66;03m# Setup metrics\u001b[39;00m\n\u001b[32m    579\u001b[39m dice_metric = DiceMetric(include_background=\u001b[38;5;28;01mFalse\u001b[39;00m, reduction=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/nix/store/y5fslgbwfjvkczl1g3ynkd0pp95j3rwg-python3.12-tqdm-4.67.1/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:192\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    180\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\n\u001b[32m    181\u001b[39m                 {\n\u001b[32m    182\u001b[39m                     key: collate(\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m                 }\n\u001b[32m    187\u001b[39m             )\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    189\u001b[39m         \u001b[38;5;66;03m# The mapping type may not support `copy()` / `update(mapping)`\u001b[39;00m\n\u001b[32m    190\u001b[39m         \u001b[38;5;66;03m# or `__init__(iterable)`.\u001b[39;00m\n\u001b[32m    191\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m             key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem\n\u001b[32m    194\u001b[39m         }\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(elem, \u001b[33m\"\u001b[39m\u001b[33m_fields\u001b[39m\u001b[33m\"\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\n\u001b[32m    197\u001b[39m         *(\n\u001b[32m    198\u001b[39m             collate(samples, collate_fn_map=collate_fn_map)\n\u001b[32m    199\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*batch)\n\u001b[32m    200\u001b[39m         )\n\u001b[32m    201\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:240\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    232\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    233\u001b[39m             \u001b[38;5;66;03m# The sequence type may not support `copy()` / `__setitem__(index, item)`\u001b[39;00m\n\u001b[32m    234\u001b[39m             \u001b[38;5;66;03m# or `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[32m    235\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    236\u001b[39m                 collate(samples, collate_fn_map=collate_fn_map)\n\u001b[32m    237\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    238\u001b[39m             ]\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format.format(elem_type))\n",
      "\u001b[31mTypeError\u001b[39m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "# Finetuning loop using the new hybrid approach\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        filename = checkpoint_path / filename\n",
    "        # Check if the finetuned checkpoint already exists\n",
    "        if filename.exists():\n",
    "            print(\n",
    "                f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images (hybrid approach)\"\n",
    "        )\n",
    "        dataset: BaseDataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            domain=domain,\n",
    "            base_path=data_path,\n",
    "            batch_size=1,\n",
    "            num_workers=0,\n",
    "            slice_2d=not use_3d,\n",
    "        )\n",
    "\n",
    "        # Use the new hybrid model method\n",
    "        model = dataset.get_hybrid_model(\n",
    "            encoder_type=\"swin_unetr\",\n",
    "            use_semantic_head=False,\n",
    "        )\n",
    "\n",
    "        head_filename =  checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baselined.pth\"\n",
    "\n",
    "        # segmentation_head = model.semantic_head\n",
    "        # torch.save(segmentation_head, head_filename)\n",
    "\n",
    "        # Save the baseline model's state_dict before finetuning\n",
    "        baseline_filename =  checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baselined.pth\"\n",
    "        torch.save(model.encoder, baseline_filename)\n",
    "        print(f\"Processing {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images (hybrid approach)\")\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline_hybrid\",\n",
    "            model_metrics,\n",
    "        )\n",
    "\n",
    "        history = model.finetune(\n",
    "            epochs=5,\n",
    "            learning_rate=1e-4,\n",
    "            weight_decay=1e-5,\n",
    "            save_best=True\n",
    "        )\n",
    "        # Save the finetuned model's state_dict\n",
    "\n",
    "        torch.save(model.encoder, filename)\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned_hybrid\",\n",
    "            model_metrics,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1df630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\")\n",
    "        baseline_checkpoint = checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        finetuned_checkpoint = checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Vector Cross-Domain Evaluation (merged version, with nested loops for all configs)\n",
    "print(\"\\n🔄 Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for source_domain in domains:\n",
    "        for target_domain in domains:\n",
    "            if source_domain == target_domain:\n",
    "                continue\n",
    "            key = (dataset_name, source_domain, target_domain)\n",
    "            metrics_key = f\"{dataset_name}_{target_domain}_from_{source_domain}_hybrid\"\n",
    "            # Only add extra_kwarg 'liver_only' for CHAOS dataset\n",
    "            extra_kwargs = {}\n",
    "            if dataset_name == \"CHAOS\":\n",
    "                extra_kwargs[\"liver_only\"] = True\n",
    "            try:\n",
    "                task_vector_key = f\"{dataset_name}_{source_domain}\"\n",
    "                if task_vector_key in task_vectors:\n",
    "                    print(f\"\\n{dataset_name}: {source_domain} → {target_domain} adaptation\")\n",
    "                    # Load target domain dataset\n",
    "                    dataset_kwargs = dict(\n",
    "                        dataset_name=dataset_name,\n",
    "                        domain=target_domain,\n",
    "                        base_path=data_path,\n",
    "                        batch_size=1,\n",
    "                        num_workers=0,\n",
    "                        slice_2d=False,\n",
    "                    )\n",
    "                    dataset_kwargs.update(extra_kwargs)\n",
    "                    target_dataset = get_dataset(**dataset_kwargs)\n",
    "                    target_model = target_dataset.get_model()\n",
    "\n",
    "                    # Apply task vector from source domain\n",
    "                    source_task_vector = task_vectors[task_vector_key]\n",
    "                    target_model.load_task_vector(source_task_vector)\n",
    "\n",
    "                    # Evaluate cross-domain performance\n",
    "                    cross_domain_metrics = target_model.evaluate()\n",
    "                    update_metrics(metrics_key, cross_domain_metrics)\n",
    "\n",
    "                    print(f\"   ✅ {source_domain}→{target_domain}: Dice={cross_domain_metrics.get('dice', 0):.3f}\")\n",
    "                    print(f\"   📊 Hausdorff Distance: {cross_domain_metrics.get('hausdorff', 0):.3f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ {dataset_name} {source_domain}→{target_domain} error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display all metrics\n",
    "metrics_file = outputs_path / \"metrics.json\"\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        all_metrics = json.load(f)\n",
    "\n",
    "    print(\"\\n📊 COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline performance\n",
    "    print(\"\\n🏁 Baseline Performance (Hybrid Semantic-Guided):\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if 'baseline' in key and 'hybrid' in key:\n",
    "            dice = metrics.get('dice', 0)\n",
    "            hausdorff = metrics.get('hausdorff', 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Cross-domain adaptation results\n",
    "    print(\"\\n🔄 Cross-Domain Adaptation Results:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if 'from' in key and 'hybrid' in key:\n",
    "            dice = metrics.get('dice', 0)\n",
    "            hausdorff = metrics.get('hausdorff', 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "else:\n",
    "    print(\"No metrics file found. Run the experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee495495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the evaluation method with fixed tensor handling\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Testing evaluation method with hybrid model...\")\n",
    "\n",
    "try:\n",
    "    # Get a small dataset for testing\n",
    "    base_path = Path(\"data\")\n",
    "    test_dataset = get_dataset(\n",
    "        dataset_name='CHAOS',\n",
    "        base_path=base_path,\n",
    "        domain='CT',\n",
    "        slice_2d=False,  # 3D\n",
    "        batch_size=1,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    print(f\"Dataset created: {type(test_dataset)}\")\n",
    "    print(f\"Number of classes: {test_dataset.num_classes}\")\n",
    "    print(f\"Class names: {test_dataset.classnames}\")\n",
    "\n",
    "    # Create hybrid model without semantic head to avoid transformer dependencies\n",
    "    hybrid_model = test_dataset.get_hybrid_model(encoder_type=\"swin_unetr\", use_semantic_head=False)\n",
    "\n",
    "    print(f\"Model created: {type(hybrid_model)}\")\n",
    "    print(f\"Model device: {next(hybrid_model.parameters()).device}\")\n",
    "\n",
    "    # Create a minimal test by getting one batch from the loader\n",
    "    test_loader = test_dataset.train_loader\n",
    "    print(f\"Dataset length: {len(test_dataset.train_dataset)}\")\n",
    "    print(f\"Loader batch size: {test_loader.batch_size}\")\n",
    "\n",
    "    batch = next(iter(test_loader))\n",
    "    print(f\"Batch image shape: {batch['image'].shape}\")\n",
    "    print(f\"Batch label shape: {batch.get('label', torch.empty(0)).shape}\")\n",
    "\n",
    "    # Test just the forward pass without evaluation metrics\n",
    "    with torch.no_grad():\n",
    "        images = batch['image']\n",
    "        print(f\"Images shape: {images.shape}\")\n",
    "        print(f\"Images min/max: {images.min():.3f}/{images.max():.3f}\")\n",
    "\n",
    "        # Test forward pass\n",
    "        output = hybrid_model(images)\n",
    "        print(f\"✓ Forward pass successful! Output shape: {output.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during test: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
