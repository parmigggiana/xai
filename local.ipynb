{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0bb3b4",
   "metadata": {},
   "source": [
    "In Kaggle, add the following to the dependencies:\n",
    "```\n",
    "pip install torch\n",
    "pip install numpy\n",
    "pip install pydicom\n",
    "pip install PILlow\n",
    "pip install matplotlib\n",
    "```\n",
    "Enable file persistence and internet access.\n",
    "Remember that you can run the whole notebook and close the runtime without wasting resources by going to File > Save Version > Save & Run All (Double check that GPU is selected in the advanced settings).\n",
    "Later, by going to 'File' > 'Version history' you can view the full logs and download the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c8f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Kaggle\n",
    "import os\n",
    "\n",
    "IN_KAGGLE = False\n",
    "if os.environ.get(\"KAGGLE_URL_BASE\", \"\"):\n",
    "    IN_KAGGLE = True\n",
    "    !git clone https://github.com/parmigggiana/xai /kaggle/working/xai\n",
    "    %cd xai\n",
    "    !git fetch\n",
    "    !git reset --hard origin/main\n",
    "    %pip install 'monai[einops,itk,nibabel]>=1.5.0' git+https://github.com/timojl/clipseg.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c6af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "IN_COLAB = False\n",
    "if not IN_KAGGLE:\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import drive\n",
    "\n",
    "        IN_COLAB = True\n",
    "        import os\n",
    "\n",
    "        drive.mount(\"/content/drive\")\n",
    "        os.makedirs(\"/content/drive/MyDrive/xai\", exist_ok=True)\n",
    "        !git clone https://github.com/parmigggiana/xai /content/xai\n",
    "        %cd /content/xai\n",
    "        !git fetch\n",
    "        !git reset --hard origin/main\n",
    "        %pip install -r requirements.txt\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector\n",
    "from src.utils import download_and_extract_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = [\"CHAOS\", \"MMWHS\"]\n",
    "DOMAINS = [\"CT\", \"MR\"]\n",
    "DATA_PATH = \"data/\"\n",
    "CHECKPOINT_PATH = \"checkpoints/\"\n",
    "OUTPUTS_PATH = \"outputs/\"\n",
    "USE_3D = False\n",
    "TRAINING_EPOCHS = {\n",
    "    (\"MMWHS\", \"CT\"): 15,\n",
    "    (\"MMWHS\", \"MR\"): 15,\n",
    "    (\"CHAOS\", \"MR\"): 15,\n",
    "    (\"CHAOS\", \"CT\"): 15,\n",
    "\n",
    "}\n",
    "BATCH_SIZE = 8\n",
    "SPATIAL_SIZE = 96\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe7c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_MAX_ITEMS = 96  # set the in-memory file cache size per dataset (images and segs)\n",
    "ENABLE_CACHE = True    # set to False to disable caching entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = Path(CHECKPOINT_PATH)\n",
    "OUTPUTS_PATH = Path(OUTPUTS_PATH)\n",
    "DATA_PATH = Path(DATA_PATH)\n",
    "CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if USE_3D:\n",
    "    encoder_type = \"swin_unetr\"\n",
    "else:\n",
    "    encoder_type = \"clipseg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai import transforms\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = OUTPUTS_PATH / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "\n",
    "def debug_metadata(data):\n",
    "    \"\"\"Debug transform to print metadata information\"\"\"\n",
    "    print(f\"🔍 DEBUG - Data type: {type(data)}\")\n",
    "    if hasattr(data, \"meta\"):\n",
    "        print(\n",
    "            f\"🔍 DEBUG - Metadata keys: {list(data.meta.keys()) if data.meta else 'No meta'}\"\n",
    "        )\n",
    "        print(f\"🔍 DEBUG - Full metadata: {data.meta}\")\n",
    "    if hasattr(data, \"shape\"):\n",
    "        print(f\"🔍 DEBUG - Shape: {data.shape}\")\n",
    "    if hasattr(data, \"dtype\"):\n",
    "        print(f\"🔍 DEBUG - Dtype: {data.dtype}\")\n",
    "    print(\"🔍 DEBUG - \" + \"=\" * 50)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Normalization stats (mean, std) per dataset/domain\n",
    "NORM_STATS = {\n",
    "    (\"MMWHS\", \"MR\"):  (186.5875, 258.5917),\n",
    "    (\"MMWHS\", \"CT\"):  (-745.0086, 1042.7251),\n",
    "    (\"CHAOS\",  \"MR\"): (90.8292, 168.8922),\n",
    "    (\"CHAOS\",  \"CT\"): (-478.1732, 476.7163),\n",
    "}\n",
    "\n",
    "# Override get_preprocessing to include normalization\n",
    "def get_preprocessing(dataset_name: str, domain: str, is_training=True):\n",
    "    decode_func = get_decode_func(dataset_name, domain)\n",
    "    mean_std = NORM_STATS.get((dataset_name, domain))\n",
    "    mean, std = (mean_std if mean_std is not None else (None, None))\n",
    "\n",
    "    # Image-specific transforms\n",
    "    if USE_3D:\n",
    "        image_transforms = [\n",
    "            transforms.EnsureChannelFirst(channel_dim=\"no_channel\"),\n",
    "            transforms.Orientation(axcodes=\"RAS\"),\n",
    "        ]\n",
    "    else:\n",
    "        image_transforms = [\n",
    "            transforms.Lambda(lambda x: x.squeeze(-1)),\n",
    "            transforms.EnsureChannelFirst(channel_dim=\"no_channel\"),\n",
    "        ]\n",
    "\n",
    "    # Augmentations (training only)\n",
    "    if is_training:\n",
    "        image_transforms.extend(\n",
    "            [\n",
    "                transforms.RandGaussianNoise(prob=0.2, std=0.05),\n",
    "                transforms.RandAdjustContrast(prob=0.2, gamma=(0.9, 1.1)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    if not USE_3D:\n",
    "        image_transforms.append(transforms.RepeatChannel(repeats=3))\n",
    "\n",
    "    # Resize -> Normalize (mean/std) -> ToTensor\n",
    "    image_transforms.extend(\n",
    "        [\n",
    "            transforms.Resize(\n",
    "                spatial_size=SPATIAL_SIZE,\n",
    "                size_mode=\"longest\",\n",
    "                mode=\"area\",\n",
    "                anti_aliasing=True,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    if mean is not None and std is not None:\n",
    "        image_transforms.append(\n",
    "            transforms.NormalizeIntensity(\n",
    "                subtrahend=float(mean),\n",
    "                divisor=float(std),\n",
    "                channel_wise=False,\n",
    "            )\n",
    "        )\n",
    "    image_transforms.extend(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.EnsureType(dtype=torch.float32),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Segmentation transforms (no normalization)\n",
    "    if not USE_3D:\n",
    "        seg_transforms = [\n",
    "            transforms.Lambda(lambda x: x.squeeze(-1)),\n",
    "            transforms.EnsureChannelFirst(channel_dim=\"no_channel\"),\n",
    "        ]\n",
    "    else:\n",
    "        seg_transforms = [\n",
    "            transforms.EnsureChannelFirst(channel_dim=\"no_channel\"),\n",
    "            transforms.Orientation(axcodes=\"RAS\"),\n",
    "        ]\n",
    "    seg_transforms.extend(\n",
    "        [\n",
    "            transforms.Lambda(lambda x: decode_func(x)),\n",
    "            transforms.Resize(\n",
    "                spatial_size=SPATIAL_SIZE, size_mode=\"longest\", mode=\"nearest\"\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.EnsureType(dtype=torch.float32),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    image_transform = transforms.Compose(image_transforms)\n",
    "    seg_transform = transforms.Compose(seg_transforms)\n",
    "    return image_transform, seg_transform\n",
    "\n",
    "\n",
    "def get_decode_func(dataset_name, domain):\n",
    "    from src.datasets.mmwhs import mmwhs_labels\n",
    "\n",
    "    decode = None\n",
    "    if dataset_name == \"CHAOS\":\n",
    "        if domain in [\"MR\", \"MRI\"]:\n",
    "            def decode(labels):\n",
    "                # Convert intensity values to class indices (keep as float32)\n",
    "                return labels // 63\n",
    "        elif domain == \"CT\":\n",
    "            def decode(labels):\n",
    "                return torch.where(labels > 0, 1.0, 0.0)\n",
    "    elif dataset_name == \"MMWHS\":\n",
    "        def decode(labels):\n",
    "            decoded_labels = torch.zeros_like(labels, dtype=torch.float32)\n",
    "            for i, label_val in enumerate(mmwhs_labels.keys()):\n",
    "                decoded_labels[labels == label_val] = i\n",
    "            return decoded_labels\n",
    "\n",
    "    if decode is None:\n",
    "        print(\n",
    "            f\"Warning: No decode function defined for {dataset_name} in {domain}. Returning labels unchanged.\"\n",
    "        )\n",
    "        def decode(labels):\n",
    "            return labels\n",
    "\n",
    "    return decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned model for MMWHS in CT domain with 2d images already exists at checkpoints\\MMWHS_CT_2d_finetuned.pth. Skipping finetuning.\n",
      "Finetuned model for MMWHS in MR domain with 2d images already exists at checkpoints\\MMWHS_MR_2d_finetuned.pth. Skipping finetuning.\n",
      "Finetuned model for CHAOS in MR domain with 2d images already exists at checkpoints\\CHAOS_MR_2d_finetuned.pth. Skipping finetuning.\n",
      "Finetuned model for CHAOS in CT domain with 2d images already exists at checkpoints\\CHAOS_CT_2d_finetuned.pth. Skipping finetuning.\n"
     ]
    }
   ],
   "source": [
    "# Finetuning loop\n",
    "\n",
    "for (dataset_name, domain), epochs in TRAINING_EPOCHS.items():\n",
    "    download_and_extract_dataset(dataset_name, DATA_PATH)\n",
    "\n",
    "    image_transform, seg_transform = get_preprocessing(\n",
    "        dataset_name, domain, is_training=True\n",
    "    )\n",
    "\n",
    "    filename = f\"{dataset_name}_{domain}_{'3d' if USE_3D else '2d'}_finetuned.pth\"\n",
    "    filename = CHECKPOINT_PATH / filename\n",
    "    # Check if the finetuned checkpoint already exists\n",
    "    if filename.exists():\n",
    "        print(\n",
    "            f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if USE_3D else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    print(\n",
    "        f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if USE_3D else '2d'} images \"\n",
    "    )\n",
    "    dataset: BaseDataset = get_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        domain=domain,\n",
    "        transform=image_transform,  # Use transform instead of preprocess\n",
    "        seg_transform=seg_transform,  # Pass seg_transform too\n",
    "        base_path=DATA_PATH,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=0,\n",
    "        slice_2d=not USE_3D,\n",
    "        # new cache knobs\n",
    "        cache_max_items=CACHE_MAX_ITEMS,\n",
    "        enable_cache=ENABLE_CACHE,\n",
    "    )\n",
    "\n",
    "\n",
    "    #  Ensure the dataset is loaded correctly\n",
    "    if not isinstance(dataset, BaseDataset):\n",
    "        raise TypeError(\n",
    "            f\"Expected dataset to be an instance of BaseDataset, got {type(dataset)}\"\n",
    "        )\n",
    "    # Print dataset information\n",
    "    print()\n",
    "    print(f\"Dataset: {dataset_name}, Domain: {domain}\")\n",
    "    print(f\"Number of training samples: {len(dataset.train_dataset)}\")\n",
    "    print(f\"Number of validation samples: {len(dataset.val_dataset)}\")\n",
    "    print(f\"Number of test samples: {len(dataset.test_dataset)}\")\n",
    "    print(f\"Image shape: {dataset.train_dataset[0]['image'].shape}\")\n",
    "    print(f\"Segmentation shape: {dataset.train_dataset[0]['label'].shape}\")\n",
    "    print(f\"Number of classes: {dataset.num_classes}\")\n",
    "    print()\n",
    "\n",
    "    model = dataset.get_model(\n",
    "        encoder_type=encoder_type,\n",
    "    )\n",
    "\n",
    "    # 🔧 DEBUG: Check initial model parameters\n",
    "    print(\"🔧 DEBUG: Initial model parameter check\")\n",
    "    initial_params = {}\n",
    "    param_count = 0\n",
    "    trainable_count = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        initial_params[name] = param.clone().detach()\n",
    "        param_count += 1\n",
    "        if param.requires_grad:\n",
    "            trainable_count += 1\n",
    "    print(f\"   Total parameters: {param_count}\")\n",
    "    print(f\"   Trainable parameters: {trainable_count}\")\n",
    "    print(f\"   Model device: {next(model.parameters()).device}\")\n",
    "    print()\n",
    "\n",
    "    # Save the baseline model's state_dict before finetuning\n",
    "    baseline_filename = (\n",
    "        CHECKPOINT_PATH\n",
    "        / f\"{dataset_name}_{domain}_{'3d' if USE_3D else '2d'}_baseline.pth\"\n",
    "    )\n",
    "    torch.save(model.encoder, baseline_filename)\n",
    "    print(\n",
    "        f\"Processing {dataset_name} in {domain} domain with {'3d' if USE_3D else '2d'} images\"\n",
    "    )\n",
    "\n",
    "    if USE_3D:\n",
    "        print(\n",
    "            f\"Warning: Using 3D model requires SWIN UNETR, which is not compatible with zero-shot training.\"\n",
    "        )\n",
    "\n",
    "        # 🔧 DEBUG: Check freeze_body functionality\n",
    "        print(\"🔧 DEBUG: Before freeze_body()\")\n",
    "        frozen_before = sum(1 for p in model.parameters() if not p.requires_grad)\n",
    "        model.freeze_body()\n",
    "        frozen_after = sum(1 for p in model.parameters() if not p.requires_grad)\n",
    "        print(f\"   Frozen parameters before: {frozen_before}\")\n",
    "        print(f\"   Frozen parameters after: {frozen_after}\")\n",
    "        print(f\"   Parameters frozen: {frozen_after - frozen_before}\")\n",
    "\n",
    "        # Check which parameters are trainable\n",
    "        print(\"   Trainable parameters after freeze_body:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f\"     {name}: {param.shape}\")\n",
    "        print()\n",
    "\n",
    "        model.finetune(\n",
    "            epochs=epochs, learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    "        )\n",
    "\n",
    "        metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if USE_3D else '2d'}_head\",\n",
    "            metrics,\n",
    "        )\n",
    "\n",
    "    # 🔧 DEBUG: Check unfreeze functionality\n",
    "    print(\"🔧 DEBUG: Before unfreeze()\")\n",
    "    frozen_before = sum(1 for p in model.parameters() if not p.requires_grad)\n",
    "    model.unfreeze()\n",
    "    frozen_after = sum(1 for p in model.parameters() if not p.requires_grad)\n",
    "    print(f\"   Frozen parameters before unfreeze: {frozen_before}\")\n",
    "    print(f\"   Frozen parameters after unfreeze: {frozen_after}\")\n",
    "    print(f\"   Total trainable parameters: {sum(1 for p in model.parameters() if p.requires_grad)}\")\n",
    "    print()\n",
    "\n",
    "    # 🔧 DEBUG: Monitor parameter changes during training\n",
    "    print(\"🔧 DEBUG: Starting full model finetuning\")\n",
    "    history = model.finetune(\n",
    "        epochs=epochs,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "\n",
    "    # 🔧 DEBUG: Check if parameters actually changed\n",
    "    print(\"🔧 DEBUG: Parameter change analysis after finetuning\")\n",
    "    changed_params = 0\n",
    "    unchanged_params = 0\n",
    "    max_change = 0.0\n",
    "    # 🔧 DEBUG: Check if parameters actually changed\n",
    "    print(\"🔧 DEBUG: Parameter change analysis after finetuning\")\n",
    "    changed_params = 0\n",
    "    unchanged_params = 0\n",
    "    max_change = 0.0\n",
    "    dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in initial_params:\n",
    "            param_dev = param.detach().to(dev)\n",
    "            initial_param_dev = initial_params[name].detach().to(dev)\n",
    "            param_change = (param_dev - initial_param_dev).norm().item()\n",
    "            if param_change > 1e-8:  # Consider very small changes as unchanged\n",
    "                changed_params += 1\n",
    "                max_change = max(max_change, param_change)\n",
    "            else:\n",
    "                unchanged_params += 1\n",
    "                print(f\"   Parameter {name} didn't change during training!\")\n",
    "\n",
    "    print(f\"   Parameters that changed: {changed_params}\")\n",
    "    print(f\"   Parameters that didn't change: {unchanged_params}\")\n",
    "    print(f\"   Maximum parameter change: {max_change:.6f}\")\n",
    "\n",
    "\n",
    "    if changed_params == 0:\n",
    "        print(\"   ⚠️ WARNING: No parameters changed during training!\")\n",
    "    elif max_change < 1e-6:\n",
    "        print(f\"   ⚠️ WARNING: Very small parameter changes (max: {max_change:.8f})\")\n",
    "    else:\n",
    "        print(\"   ✅ Parameters updated successfully\")\n",
    "    print()\n",
    "\n",
    "    # 🔧 DEBUG: Check training history\n",
    "    if history:\n",
    "        print(\"🔧 DEBUG: Training history analysis\")\n",
    "        if 'train_loss' in history:\n",
    "            train_losses = history['train_loss']\n",
    "            print(f\"   Training losses: {train_losses[:5]}...{train_losses[-5:] if len(train_losses) > 5 else train_losses}\")\n",
    "            print(f\"   Loss range: {min(train_losses):.6f} - {max(train_losses):.6f}\")\n",
    "            if len(train_losses) > 1:\n",
    "                loss_change = abs(train_losses[-1] - train_losses[0])\n",
    "                print(f\"   Total loss change: {loss_change:.6f}\")\n",
    "                if loss_change < 1e-6:\n",
    "                    print(\"   ⚠️ WARNING: Training loss barely changed!\")\n",
    "        else:\n",
    "            print(\"   ⚠️ No 'train_loss' found in history\")\n",
    "        print(f\"   History keys: {list(history.keys()) if history else 'None'}\")\n",
    "    else:\n",
    "        print(\"🔧 DEBUG: No training history returned\")\n",
    "    print()\n",
    "\n",
    "    # Save the finetuned model's state_dict\n",
    "    torch.save(model.encoder, filename)\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if USE_3D else '2d'}_finetuned\",\n",
    "        model_metrics,\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54f4f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building task vector for CHAOS dataset in CT domain with 2d images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building task vector for CHAOS dataset in MR domain with 2d images\n",
      "Building task vector for MMWHS dataset in CT domain with 2d images\n",
      "Building task vector for MMWHS dataset in MR domain with 2d images\n"
     ]
    }
   ],
   "source": [
    "# SWIN UNETR Task Vectors\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.networks.nets.swin_unetr import SwinTransformer\n",
    "from monai.networks.blocks.patchembedding import PatchEmbed\n",
    "from torch.nn.modules.conv import Conv3d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.container import ModuleList\n",
    "from monai.networks.nets.swin_unetr import BasicLayer\n",
    "from monai.networks.nets.swin_unetr import SwinTransformerBlock\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "from monai.networks.nets.swin_unetr import WindowAttention\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch.nn.modules.activation import Softmax\n",
    "from torch.nn.modules.linear import Identity\n",
    "from monai.networks.blocks.mlp import MLPBlock\n",
    "from torch.nn.modules.activation import GELU\n",
    "from monai.networks.nets.swin_unetr import PatchMerging\n",
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock\n",
    "from monai.networks.blocks.dynunet_block import UnetResBlock\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "from torch.nn.modules.activation import LeakyReLU\n",
    "from torch.nn.modules.instancenorm import InstanceNorm3d\n",
    "from monai.networks.blocks.unetr_block import UnetrUpBlock\n",
    "from monai.networks.blocks.dynunet_block import UnetOutBlock\n",
    "from torch.nn.modules.conv import ConvTranspose3d\n",
    "\n",
    "safe_globals = [\n",
    "    SwinUNETR,\n",
    "    SwinTransformer,\n",
    "    PatchEmbed,\n",
    "    Conv3d,\n",
    "    Dropout,\n",
    "    ModuleList,\n",
    "    BasicLayer,\n",
    "    SwinTransformerBlock,\n",
    "    LayerNorm,\n",
    "    WindowAttention,\n",
    "    Linear,\n",
    "    Softmax,\n",
    "    Identity,\n",
    "    MLPBlock,\n",
    "    GELU,\n",
    "    PatchMerging,\n",
    "    UnetrBasicBlock,\n",
    "    UnetResBlock,\n",
    "    Convolution,\n",
    "    LeakyReLU,\n",
    "    InstanceNorm3d,\n",
    "    UnetrUpBlock,\n",
    "    ConvTranspose3d,\n",
    "    UnetOutBlock,\n",
    "]\n",
    "##\n",
    "\n",
    "## CLIPSeg Task Vectors\n",
    "from src.CLIPSeg import CLIPSeg\n",
    "from clipseg.clipseg import CLIPDensePredT\n",
    "from clip.model import (\n",
    "    CLIP,\n",
    "    VisionTransformer,\n",
    "    LayerNorm,\n",
    "    Transformer,\n",
    "    ResidualAttentionBlock,\n",
    "    QuickGELU,\n",
    ")\n",
    "from torch.nn.modules.conv import Conv2d, ConvTranspose2d\n",
    "from torch.nn.modules.container import Sequential\n",
    "from torch.nn.modules.activation import MultiheadAttention, ReLU\n",
    "from torch.nn.modules.linear import NonDynamicallyQuantizableLinear\n",
    "from torch.nn.modules.sparse import Embedding\n",
    "from torch.nn.modules.transformer import (\n",
    "    TransformerEncoderLayer,\n",
    "    TransformerEncoder,\n",
    "    TransformerDecoderLayer,\n",
    "    TransformerDecoder,\n",
    ")\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn.modules.container import ModuleDict\n",
    "\n",
    "safe_globals.extend(\n",
    "    [\n",
    "        CLIPSeg,\n",
    "        CLIPDensePredT,\n",
    "        CLIP,\n",
    "        VisionTransformer,\n",
    "        Conv2d,\n",
    "        LayerNorm,\n",
    "        Transformer,\n",
    "        Sequential,\n",
    "        ResidualAttentionBlock,\n",
    "        MultiheadAttention,\n",
    "        NonDynamicallyQuantizableLinear,\n",
    "        QuickGELU,\n",
    "        Embedding,\n",
    "        ReLU,\n",
    "        ConvTranspose2d,\n",
    "        TransformerEncoderLayer,\n",
    "        TransformerEncoder,\n",
    "        TransformerDecoderLayer,\n",
    "        TransformerDecoder,\n",
    "        relu,\n",
    "        ModuleDict,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    for domain in DOMAINS:\n",
    "        print(\n",
    "            f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if USE_3D else '2d'} images\"\n",
    "        )\n",
    "        baseline_checkpoint = (\n",
    "            CHECKPOINT_PATH\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if USE_3D else '2d'}_baseline.pth\"\n",
    "        )\n",
    "        finetuned_checkpoint = (\n",
    "            CHECKPOINT_PATH\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if USE_3D else '2d'}_finetuned.pth\"\n",
    "        )\n",
    "        if not baseline_checkpoint.exists():\n",
    "            print(\n",
    "                f\"Baseline checkpoint for {dataset_name} {domain} does not exist. Skipping task vector creation.\"\n",
    "            )\n",
    "            continue\n",
    "        if not finetuned_checkpoint.exists():\n",
    "            print(\n",
    "                f\"Finetuned checkpoint {dataset_name} {domain} does not exist. Skipping task vector creation.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        with torch.serialization.safe_globals(\n",
    "            safe_globals=safe_globals,\n",
    "        ):\n",
    "            task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "            # Remove keys associated with the output layers from the task vector\n",
    "            # For swin it's all layers starting with '.out'\n",
    "            # For clipseg it might not be necessary since the model architecture isn't dependent on the number of output features\n",
    "            if encoder_type == \"swin_unetr\":\n",
    "                for k in task_vector.keys():\n",
    "                    if k.startswith(\".out\"):\n",
    "                        del task_vector[k]\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee4dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Simple Composite Task Vector — computing ONLY 4 metrics (averaged over selected dataset/domain pairs)\n",
      "================================================================================\n",
      "\n",
      "▶ MMWHS_CT_MR (2 targets)\n",
      "  - MMWHS/CT\n",
      "\n",
      "▶ MMWHS_CT_MR (2 targets)\n",
      "  - MMWHS/CT\n",
      "Dataset CT total samples: 5305\n",
      "Split sizes - Train: 3713, Val: 795, Test: 797\n",
      "Dataset CT total samples: 5305\n",
      "Split sizes - Train: 3713, Val: 795, Test: 797\n",
      "Found explicit background class in input. Treating it separately.\n",
      "Non-background classes: ['Left ventricle blood cavity', 'Right ventricle blood cavity', 'Left atrium blood cavity', 'Right atrium blood cavity', 'Myocardium of the left ventricle', 'Ascending aorta', 'Pulmonary artery']\n",
      "Found explicit background class in input. Treating it separately.\n",
      "Non-background classes: ['Left ventricle blood cavity', 'Right ventricle blood cavity', 'Left atrium blood cavity', 'Right atrium blood cavity', 'Myocardium of the left ventricle', 'Ascending aorta', 'Pulmonary artery']\n",
      "🔄 Loading CLIPSeg weights...\n",
      "🔄 Loading CLIPSeg weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:   0%|          | 0/465 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 🔄 Simple Composite Task Vector: 4 clear metrics only\n",
    "\n",
    "# Define the four simple composite vectors\n",
    "composite_task_vectors_simple = {\n",
    "    \"MMWHS\": (task_vectors[\"MMWHS_MR\"] + task_vectors[\"MMWHS_CT\"]),   # MMWHS CT+MR\n",
    "    \"CHAOS\": (task_vectors[\"CHAOS_MR\"] + task_vectors[\"CHAOS_CT\"]),    # CHAOS CT+MR\n",
    "    \"MR\":    (task_vectors[\"CHAOS_MR\"] + task_vectors[\"MMWHS_MR\"]),    # MR across datasets\n",
    "    \"CT\":    (task_vectors[\"CHAOS_CT\"] + task_vectors[\"MMWHS_CT\"]),    # CT across datasets\n",
    "}\n",
    "\n",
    "print(\"🔄 Simple Composite Task Vector — computing ONLY 4 metrics (averaged over selected dataset/domain pairs)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "# Map each composite vector to the evaluation targets\n",
    "# - MMWHS_CT_MR: evaluate on MMWHS CT and MR\n",
    "# - CHAOS_CT_MR: evaluate on CHAOS CT and MR\n",
    "# - CT_both_datasets: evaluate on CT of both datasets\n",
    "# - MR_both_datasets: evaluate on MR of both datasets\n",
    "vectors_to_test = {\n",
    "    \"MMWHS_CT_MR\": composite_task_vectors_simple[\"MMWHS\"],          # MMWHS (CT+MR)\n",
    "    \"CHAOS_CT_MR\": composite_task_vectors_simple[\"CHAOS\"],          # CHAOS (CT+MR)\n",
    "    \"CT_both_datasets\": composite_task_vectors_simple[\"CT\"],        # CT across datasets\n",
    "    \"MR_both_datasets\": composite_task_vectors_simple[\"MR\"],        # MR across datasets\n",
    "}\n",
    "\n",
    "target_groups = {\n",
    "    \"MMWHS_CT_MR\": [(\"MMWHS\", \"CT\"), (\"MMWHS\", \"MR\")],\n",
    "    \"CHAOS_CT_MR\": [(\"CHAOS\", \"CT\"), (\"CHAOS\", \"MR\")],\n",
    "    \"CT_both_datasets\": [(\"CHAOS\", \"CT\"), (\"MMWHS\", \"CT\")],\n",
    "    \"MR_both_datasets\": [(\"CHAOS\", \"MR\"), (\"MMWHS\", \"MR\")],\n",
    "}\n",
    "\n",
    "# Evaluate only the selected target pairs and average Dice over them (4 metrics total)\n",
    "for label, composite_vec in vectors_to_test.items():\n",
    "    pairs = target_groups[label]\n",
    "    print(f\"\\n▶ {label} ({len(pairs)} targets)\")\n",
    "    scores = []\n",
    "\n",
    "    for (dataset_name, target_domain) in pairs:\n",
    "        print(f\"  - {dataset_name}/{target_domain}\")\n",
    "\n",
    "        image_transform, seg_transform = get_preprocessing(\n",
    "            dataset_name, target_domain, is_training=False\n",
    "        )\n",
    "\n",
    "        dataset_kwargs = {\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"base_path\": DATA_PATH,\n",
    "            \"domain\": target_domain,\n",
    "            \"transform\": image_transform,  # Use transform instead of preprocess\n",
    "            \"seg_transform\": seg_transform,  # Pass seg_transform too\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"num_workers\": 0,\n",
    "            \"slice_2d\": not USE_3D,\n",
    "            # pass cache knobs as well\n",
    "            \"cache_max_items\": CACHE_MAX_ITEMS,\n",
    "            \"enable_cache\": ENABLE_CACHE,\n",
    "        }\n",
    "        extra_kwargs = {}\n",
    "        if dataset_name == \"CHAOS\":\n",
    "            extra_kwargs[\"liver_only\"] = True\n",
    "\n",
    "        # Build target dataset and model\n",
    "        target_dataset = get_dataset(**dataset_kwargs, **extra_kwargs)\n",
    "        target_model = target_dataset.get_model(encoder_type=encoder_type)\n",
    "\n",
    "        # Load and evaluate the composite task vector\n",
    "        target_model.load_task_vector(composite_vec)\n",
    "        metrics = target_model.evaluate()\n",
    "        dice = metrics.get(\"train\", {}).get(\"dice\", 0.0)\n",
    "        scores.append(float(dice))\n",
    "        print(f\"    Dice={float(dice):.3f}\")\n",
    "\n",
    "    avg_dice = mean(scores) if scores else 0.0\n",
    "    update_metrics(f\"{label}_avg\", {\"dice\": avg_dice, \"n\": len(scores)})\n",
    "    print(f\"✅ {label}: avg Dice={avg_dice:.3f}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build composite task vectors using arithmetic\n",
    "composite_task_vectors = {\n",
    "    \"MMWHS_CT\": task_vectors[\"MMWHS_MR\"]\n",
    "    + task_vectors[\"CHAOS_CT\"]\n",
    "    - task_vectors[\"CHAOS_MR\"],\n",
    "    \"MMWHS_MR\": task_vectors[\"MMWHS_CT\"]\n",
    "    + task_vectors[\"CHAOS_MR\"]\n",
    "    - task_vectors[\"CHAOS_CT\"],\n",
    "    \"CHAOS_CT\": task_vectors[\"CHAOS_MR\"]\n",
    "    + task_vectors[\"MMWHS_CT\"]\n",
    "    - task_vectors[\"MMWHS_MR\"],\n",
    "    \"CHAOS_MR\": task_vectors[\"CHAOS_CT\"]\n",
    "    + task_vectors[\"MMWHS_MR\"]\n",
    "    - task_vectors[\"MMWHS_CT\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Task Vector Cross-Domain Adaptation Experiments\n",
    "print(\"🔄 Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    for target_domain in DOMAINS:\n",
    "        print(f\"\\n{dataset_name}: {target_domain} adaptation\")\n",
    "\n",
    "        image_transform, seg_transform = get_preprocessing(\n",
    "            dataset_name, target_domain, is_training=False\n",
    "        )\n",
    "\n",
    "        dataset_kwargs = {\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"base_path\": DATA_PATH,\n",
    "            \"domain\": target_domain,\n",
    "            \"transform\": image_transform,  # Use transform instead of preprocess\n",
    "            \"seg_transform\": seg_transform,  # Pass seg_transform too\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"num_workers\": 0,\n",
    "            \"slice_2d\": not USE_3D,\n",
    "            # pass cache knobs as well\n",
    "            \"cache_max_items\": CACHE_MAX_ITEMS,\n",
    "            \"enable_cache\": ENABLE_CACHE,\n",
    "        }\n",
    "        extra_kwargs = {}\n",
    "        if dataset_name == \"CHAOS\":\n",
    "            extra_kwargs[\"liver_only\"] = True\n",
    "\n",
    "        # try:\n",
    "        target_dataset = get_dataset(**dataset_kwargs, **extra_kwargs)\n",
    "\n",
    "        composite_key = f\"{dataset_name}_{target_domain}\"\n",
    "        if composite_key in composite_task_vectors:\n",
    "            composite_task_vector = composite_task_vectors[composite_key]\n",
    "\n",
    "            target_model = target_dataset.get_model(encoder_type=encoder_type)\n",
    "            target_model.load_task_vector(composite_task_vector)\n",
    "\n",
    "            metrics = target_model.evaluate()\n",
    "            update_metrics(f\"{composite_key}_adaptation\", metrics)\n",
    "            print(\n",
    "                f\"   ✅ {composite_key}: Dice={metrics.get('train', {}).get('dice', 0):.3f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(f\"   ⚠️ No composite task vector found for {composite_key}\")\n",
    "\n",
    "        # except Exception as e:\n",
    "        #     print(f\"   ❌ {dataset_name} {target_domain}: {str(e)[:100]}...\")\n",
    "        #     import traceback\n",
    "        #     traceback.print_exc()\n",
    "        #     # continue\n",
    "        #     break\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import shutil\n",
    "\n",
    "    # Copy checkpoints.zip to Google Drive\n",
    "    !zip -r /content/checkpoints.zip /content/xai/checkpoints\n",
    "    shutil.copy(\n",
    "        \"/content/checkpoints.zip\", \"/content/drive/MyDrive/xai/checkpoints.zip\"\n",
    "    )\n",
    "\n",
    "    # Copy metrics.json to Google Drive\n",
    "    shutil.copy(\n",
    "        \"/content/xai/outputs/metrics.json\", \"/content/drive/MyDrive/xai/metrics.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE:\n",
    "    !zip -r /kaggle/working/checkpoints.zip /kaggle/working/xai/checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f3841",
   "metadata": {},
   "source": [
    "# Statistiche dei 4 dataset (CHAOS/MMWHS × CT/MR)\n",
    "Questo blocco calcola e visualizza statistiche per ciascuna combinazione dataset/dominio:\n",
    "- Dimensioni degli split (train/val/test)\n",
    "- Forma media di immagini e maschere\n",
    "- Statistiche di intensità (min/max/media/dev.std) su un sottoinsieme del train\n",
    "- Distribuzione delle classi (bar chart) sul sottoinsieme del train\n",
    "\n",
    "Nota: per rapidità, le statistiche vengono calcolate su un sottoinsieme dei primi N campioni del train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "SUBSET_N = 1e16-1  # numero massimo di campioni del train da usare per le statistiche\n",
    "PRINT_EVERY = 8\n",
    "\n",
    "# helper: estrai numpy dai MetaTensor o torch.Tensor\n",
    "\n",
    "def to_numpy(x):\n",
    "    if hasattr(x, \"detach\"):\n",
    "        x = x.detach()\n",
    "    if hasattr(x, \"cpu\"):\n",
    "        x = x.cpu()\n",
    "    return np.asarray(x)\n",
    "\n",
    "\n",
    "def class_histogram(labels_np):\n",
    "    # considera solo valori >=0\n",
    "    flat = labels_np.astype(np.int64).ravel()\n",
    "    flat = flat[flat >= 0]\n",
    "    counts = Counter(flat.tolist())\n",
    "    return counts\n",
    "\n",
    "\n",
    "def summarize_split(loader, max_items=SUBSET_N):\n",
    "    n = 0\n",
    "    shapes_img, shapes_seg = [], []\n",
    "    stats = {\n",
    "        \"img_min\": [],\n",
    "        \"img_max\": [],\n",
    "        \"img_mean\": [],\n",
    "        \"img_std\": [],\n",
    "        \"class_counts\": Counter(),\n",
    "    }\n",
    "    if loader is None:\n",
    "        return {\n",
    "            \"n_seen\": 0,\n",
    "            \"img_shape_examples\": [],\n",
    "            \"seg_shape_examples\": [],\n",
    "            \"img_min\": None,\n",
    "            \"img_max\": None,\n",
    "            \"img_mean\": None,\n",
    "            \"img_std\": None,\n",
    "            \"class_hist\": {},\n",
    "        }\n",
    "    for batch in loader:\n",
    "        img = batch.get(\"image\")\n",
    "        seg = batch.get(\"label\")\n",
    "        if img is None:\n",
    "            continue\n",
    "        # img/seg possono essere MetaTensor con shape (B, C, H, W) o (B, C, H, W, D)\n",
    "        img_np = to_numpy(img)\n",
    "        stats[\"img_min\"].append(float(img_np.min()))\n",
    "        stats[\"img_max\"].append(float(img_np.max()))\n",
    "        stats[\"img_mean\"].append(float(img_np.mean()))\n",
    "        stats[\"img_std\"].append(float(img_np.std()))\n",
    "        shapes_img.append(tuple(img_np.shape))\n",
    "        if seg is not None:\n",
    "            seg_np = to_numpy(seg)\n",
    "            shapes_seg.append(tuple(seg_np.shape))\n",
    "            stats[\"class_counts\"].update(class_histogram(seg_np))\n",
    "        n += img_np.shape[0]\n",
    "        if n >= max_items:\n",
    "            break\n",
    "    # aggrega\n",
    "    agg = {\n",
    "        \"n_seen\": n,\n",
    "        \"img_shape_examples\": shapes_img[: min(3, len(shapes_img))],\n",
    "        \"seg_shape_examples\": shapes_seg[: min(3, len(shapes_seg))],\n",
    "        \"img_min\": float(np.mean(stats[\"img_min\"])) if stats[\"img_min\"] else None,\n",
    "        \"img_max\": float(np.mean(stats[\"img_max\"])) if stats[\"img_max\"] else None,\n",
    "        \"img_mean\": float(np.mean(stats[\"img_mean\"])) if stats[\"img_mean\"] else None,\n",
    "        \"img_std\": float(np.mean(stats[\"img_std\"])) if stats[\"img_std\"] else None,\n",
    "        \"class_hist\": dict(stats[\"class_counts\"]),\n",
    "    }\n",
    "    return agg\n",
    "\n",
    "\n",
    "def plot_histogram(hist_dict, title, classnames=None):\n",
    "    if not hist_dict:\n",
    "        print(f\"   Nessuna maschera/nessuna classe trovata per {title}\")\n",
    "        return\n",
    "    keys = sorted(hist_dict.keys())\n",
    "    vals = [hist_dict[k] for k in keys]\n",
    "    labels = [classnames[k] if classnames and k < len(classnames) else str(k) for k in keys]\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.bar(range(len(keys)), vals)\n",
    "    plt.xticks(range(len(keys)), labels, rotation=45, ha=\"right\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "all_stats = {}\n",
    "\n",
    "for dataset_name in DATASET_NAMES:\n",
    "    for domain in DOMAINS:\n",
    "        print(f\"\\n== {dataset_name} / {domain} ==\")\n",
    "        image_transform, seg_transform = get_preprocessing(dataset_name, domain, is_training=False)\n",
    "        extra_kwargs = {}\n",
    "        if dataset_name == \"CHAOS\" and domain == \"MR\":\n",
    "            # opzionale: limita a fegato\n",
    "            extra_kwargs[\"liver_only\"] = False\n",
    "\n",
    "        ds = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            base_path=DATA_PATH,\n",
    "            domain=domain,\n",
    "            transform=image_transform,\n",
    "            seg_transform=seg_transform,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            num_workers=0,\n",
    "            slice_2d=not USE_3D,\n",
    "            cache_max_items=CACHE_MAX_ITEMS,\n",
    "            enable_cache=ENABLE_CACHE,\n",
    "            **extra_kwargs,\n",
    "        )\n",
    "\n",
    "        # dimensioni split\n",
    "        n_train = len(ds.train_dataset) if ds.train_dataset is not None else 0\n",
    "        n_val = len(ds.val_dataset) if ds.val_dataset is not None else 0\n",
    "        n_test = len(ds.test_dataset) if ds.test_dataset is not None else 0\n",
    "        print(f\"Split -> train: {n_train}, val: {n_val}, test: {n_test}\")\n",
    "        print(f\"Num classi: {getattr(ds, 'num_classes', 'N/A')} | Classnames: {getattr(ds, 'classnames', None)}\")\n",
    "\n",
    "        # statistiche su subset del train\n",
    "        train_stats = summarize_split(ds.train_loader, SUBSET_N)\n",
    "        imin = train_stats['img_min']\n",
    "        imax = train_stats['img_max']\n",
    "        imean = train_stats['img_mean']\n",
    "        istd = train_stats['img_std']\n",
    "        fmt = lambda v: (f\"{v:.4f}\" if isinstance(v, (int, float)) else \"N/A\")\n",
    "        print(f\"   Visti nel subset: {train_stats['n_seen']}\")\n",
    "        print(f\"   Esempi img shape: {train_stats['img_shape_examples']}\")\n",
    "        print(f\"   Esempi seg shape: {train_stats['seg_shape_examples']}\")\n",
    "        print(\n",
    "            f\"   Intensità ~ min:{fmt(imin)} max:{fmt(imax)} \"\n",
    "            f\"mean:{fmt(imean)} std:{fmt(istd)}\"\n",
    "        )\n",
    "\n",
    "        all_stats[f\"{dataset_name}_{domain}\"] = {\n",
    "            \"splits\": {\"train\": n_train, \"val\": n_val, \"test\": n_test},\n",
    "            \"subset\": train_stats,\n",
    "            \"classnames\": getattr(ds, \"classnames\", None),\n",
    "        }\n",
    "\n",
    "        # bar chart distribuzione classi\n",
    "        plot_histogram(\n",
    "            train_stats[\"class_hist\"],\n",
    "            title=f\"Distribuzione classi (subset) - {dataset_name} {domain}\",\n",
    "            classnames=ds.classnames if hasattr(ds, \"classnames\") else None,\n",
    "        )\n",
    "\n",
    "# salva riepilogo su file\n",
    "try:\n",
    "    out_file = OUTPUTS_PATH / \"dataset_stats.json\"\n",
    "    with open(out_file, \"w\") as f:\n",
    "        json.dump(all_stats, f, indent=2)\n",
    "    print(f\"\\nSalvato riepilogo in: {out_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore salvataggio stats: {e}\")\n",
    "\n",
    "print(\"\\nRiepilogo sintetico:\")\n",
    "for k, v in all_stats.items():\n",
    "    s = v[\"splits\"]\n",
    "    print(f\" - {k}: train={s['train']}, val={s['val']}, test={s['test']} | visti(subset)={v['subset']['n_seen']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
