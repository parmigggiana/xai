{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f6157a",
   "metadata": {},
   "source": [
    "The original task arithmetic paper uses CLIP and builds classification heads with zero-shot training based on some templates.\n",
    "In our case, we have some special characteristics to keep in mind:\n",
    "- We are operating on medical, 3D, data.\n",
    "- Our objective is semantic labeling, not simple classification.\n",
    "\n",
    "To deal with this we have a couple of options to try:\n",
    "- Copy the same flow using CLIP trained on imagenet and slice the 3d images into multiple 2d.\n",
    "    - Since we need to do segmentation, we need to find a model that can perform segmentation and be finetuned\n",
    "    - Even better if we access separately the segmentation head and the encoder\n",
    "- Use 3d resnet pretrained on medicalnet by monai, perform a few short training loops with frozen encoder to train the segmentation head. \n",
    "- Use medsam/medsam2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MMWHS\"]\n",
    "domains = [\"CT\", \"MR\"]\n",
    "data_path = 'data/'\n",
    "checkpoint_path = \"checkpoints/\"\n",
    "outputs_path = \"outputs/\"\n",
    "use_3d = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "data_path = Path(data_path)\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = outputs_path / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "                metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning on CHAOS dataset in CT domain with 3d images (hybrid approach)\n",
      "Batch size: torch.Size([1, 1, 257, 512, 512]) - RAM: 2538.2MB\n",
      "Batch size: torch.Size([1, 1, 257, 512, 512]) - RAM: 2538.2MB\n"
     ]
    }
   ],
   "source": [
    "# Finetuning loop using the new hybrid approach\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        filename = checkpoint_path / filename\n",
    "        # Check if the finetuned checkpoint already exists\n",
    "        if filename.exists():\n",
    "            print(\n",
    "                f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images (hybrid approach)\"\n",
    "        )\n",
    "        dataset: BaseDataset = get_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            domain=domain,\n",
    "            base_path=data_path,\n",
    "            batch_size=1,\n",
    "            num_workers=0,\n",
    "            slice_2d=not use_3d,\n",
    "        )\n",
    "\n",
    "        # Use the new hybrid model method\n",
    "        model = dataset.get_hybrid_model(\n",
    "            encoder_type=\"resnet\",\n",
    "            use_semantic_head=True,\n",
    "        )\n",
    "\n",
    "        head_filename =  checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baselined.pth\"\n",
    "        segmentation_head = model.semantic_head\n",
    "        torch.save(segmentation_head, head_filename)\n",
    "\n",
    "        # Save the baseline model's state_dict before finetuning\n",
    "        baseline_filename =  checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baselined.pth\"\n",
    "        torch.save(model.encoder, baseline_filename)\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline_hybrid\",\n",
    "            model_metrics,\n",
    "        )\n",
    "\n",
    "        model.finetune(\n",
    "            epochs=5,\n",
    "        )\n",
    "        # Save the finetuned model's state_dict\n",
    "\n",
    "        torch.save(model.encoder, filename)\n",
    "        model_metrics = model.evaluate()\n",
    "        update_metrics(\n",
    "            f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned_hybrid\",\n",
    "            model_metrics,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1df630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building task vector for CHAOS dataset in CT domain with 3d images\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'checkpoints/CHAOS_CT_3d_baseline.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m baseline_checkpoint = checkpoint_path / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m3d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39muse_3d\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m2d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_baseline.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m finetuned_checkpoint = checkpoint_path / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m3d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39muse_3d\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m2d\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_finetuned.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m task_vector = \u001b[43mTaskVector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_checkpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinetuned_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m task_vectors[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = task_vector\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/src/task_vector.py:25\u001b[39m, in \u001b[36mTaskVector.__init__\u001b[39m\u001b[34m(self, pretrained_checkpoint, finetuned_checkpoint, vector)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m     22\u001b[39m     pretrained_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m finetuned_checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     pretrained_state_dict = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_checkpoint\u001b[49m\u001b[43m)\u001b[49m.state_dict()\n\u001b[32m     26\u001b[39m     finetuned_state_dict = torch.load(finetuned_checkpoint).state_dict()\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mself\u001b[39m.vector = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/serialization.py:1425\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1423\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1427\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1428\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1429\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1430\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/serialization.py:751\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    750\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m751\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Magistrale/Anno2_Semestre2/Explainable_and_Trustworthy_AI/project/.venv/lib/python3.12/site-packages/torch/serialization.py:732\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'checkpoints/CHAOS_CT_3d_baseline.pth'"
     ]
    }
   ],
   "source": [
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\")\n",
    "        baseline_checkpoint = checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        finetuned_checkpoint = checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Vector Cross-Domain Evaluation (merged version, with nested loops for all configs)\n",
    "print(\"\\nðŸ”„ Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for dataset_name in dataset_names:\n",
    "    for source_domain in domains:\n",
    "        for target_domain in domains:\n",
    "            if source_domain == target_domain:\n",
    "                continue\n",
    "            key = (dataset_name, source_domain, target_domain)\n",
    "            metrics_key = f\"{dataset_name}_{target_domain}_from_{source_domain}_hybrid\"\n",
    "            # Only add extra_kwarg 'liver_only' for CHAOS dataset\n",
    "            extra_kwargs = {}\n",
    "            if dataset_name == \"CHAOS\":\n",
    "                extra_kwargs[\"liver_only\"] = True\n",
    "            try:\n",
    "                task_vector_key = f\"{dataset_name}_{source_domain}\"\n",
    "                if task_vector_key in task_vectors:\n",
    "                    print(f\"\\n{dataset_name}: {source_domain} â†’ {target_domain} adaptation\")\n",
    "                    # Load target domain dataset\n",
    "                    dataset_kwargs = dict(\n",
    "                        dataset_name=dataset_name,\n",
    "                        domain=target_domain,\n",
    "                        base_path=data_path,\n",
    "                        batch_size=1,\n",
    "                        num_workers=0,\n",
    "                        slice_2d=False,\n",
    "                    )\n",
    "                    dataset_kwargs.update(extra_kwargs)\n",
    "                    target_dataset = get_dataset(**dataset_kwargs)\n",
    "                    target_model = target_dataset.get_model()\n",
    "\n",
    "                    # Apply task vector from source domain\n",
    "                    source_task_vector = task_vectors[task_vector_key]\n",
    "                    target_model.load_task_vector(source_task_vector)\n",
    "\n",
    "                    # Evaluate cross-domain performance\n",
    "                    cross_domain_metrics = target_model.evaluate()\n",
    "                    update_metrics(metrics_key, cross_domain_metrics)\n",
    "\n",
    "                    print(f\"   âœ… {source_domain}â†’{target_domain}: Dice={cross_domain_metrics.get('dice', 0):.3f}\")\n",
    "                    print(f\"   ðŸ“Š Hausdorff Distance: {cross_domain_metrics.get('hausdorff', 0):.3f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ {dataset_name} {source_domain}â†’{target_domain} error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display all metrics\n",
    "metrics_file = outputs_path / \"metrics.json\"\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        all_metrics = json.load(f)\n",
    "\n",
    "    print(\"\\nðŸ“Š COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline performance\n",
    "    print(\"\\nðŸ Baseline Performance (Hybrid Semantic-Guided):\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if 'baseline' in key and 'hybrid' in key:\n",
    "            dice = metrics.get('dice', 0)\n",
    "            hausdorff = metrics.get('hausdorff', 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Cross-domain adaptation results\n",
    "    print(\"\\nðŸ”„ Cross-Domain Adaptation Results:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if 'from' in key and 'hybrid' in key:\n",
    "            dice = metrics.get('dice', 0)\n",
    "            hausdorff = metrics.get('hausdorff', 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "else:\n",
    "    print(\"No metrics file found. Run the experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee495495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the evaluation method with fixed tensor handling\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Testing evaluation method with hybrid model...\")\n",
    "\n",
    "try:\n",
    "    # Get a small dataset for testing\n",
    "    base_path = Path(\"data\")\n",
    "    test_dataset = get_dataset('CHAOS', base_path, use_3d=True, train=True, domain='CT')\n",
    "\n",
    "    # Create hybrid model without semantic head to avoid transformer dependencies\n",
    "    hybrid_model = test_dataset.get_hybrid_model(encoder_type=\"swin_unetr\", use_semantic_head=False)\n",
    "\n",
    "    print(f\"Model created: {type(hybrid_model)}\")\n",
    "    print(f\"Model device: {next(hybrid_model.parameters()).device}\")\n",
    "\n",
    "    # Create a minimal test by getting one batch from the loader\n",
    "    test_loader = test_dataset.train_loader\n",
    "    batch = next(iter(test_loader))\n",
    "    print(f\"Batch image shape: {batch['image'].shape}\")\n",
    "    print(f\"Batch label shape: {batch.get('label', torch.empty(0)).shape}\")\n",
    "\n",
    "    # Test just the forward pass without evaluation metrics\n",
    "    with torch.no_grad():\n",
    "        images = batch['image']\n",
    "        # Check if we need to slice for SwinUNETR dimension requirements\n",
    "        if images.shape[2] >= 32:  # Depth dimension\n",
    "            sliced_images = images[:, :, :32, :, :].contiguous()\n",
    "            print(f\"Sliced images shape: {sliced_images.shape}\")\n",
    "            output = hybrid_model(sliced_images)\n",
    "            print(f\"âœ“ Forward pass successful! Output shape: {output.shape}\")\n",
    "        else:\n",
    "            print(f\"Image depth {images.shape[2]} < 32, cannot test with SwinUNETR\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during test: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
