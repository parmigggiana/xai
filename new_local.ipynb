{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0bb3b4",
   "metadata": {},
   "source": [
    "In Kaggle, add the following to the dependencies:\n",
    "```\n",
    "pip install torch\n",
    "pip install torchvision\n",
    "pip install numpy\n",
    "pip install pydicom\n",
    "pip install PILlow\n",
    "pip install matplotlib\n",
    "```\n",
    "Enable file persistence and internet access.\n",
    "Remember that you can run the whole notebook and close the runtime without wasting resources by going to File > Save Version > Save & Run All (Double check that GPU is selected in the advanced settings).\n",
    "Later, by going to 'File' > 'Version history' you can view the full logs and download the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Kaggle\n",
    "import os\n",
    "\n",
    "IN_KAGGLE = False\n",
    "if os.environ.get(\"KAGGLE_URL_BASE\", \"\"):\n",
    "    IN_KAGGLE = True\n",
    "    !git clone https://github.com/parmigggiana/xai /kaggle/working/xai\n",
    "    %cd xai\n",
    "    !git fetch\n",
    "    !git reset --hard origin/main\n",
    "    %pip install 'monai[einops,itk]>=1.5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "IN_COLAB = False\n",
    "if not IN_KAGGLE:\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import drive\n",
    "        IN_COLAB = True\n",
    "        import os\n",
    "        drive.mount('/content/drive')\n",
    "        os.makedirs('/content/drive/MyDrive/xai', exist_ok=True)\n",
    "        !git clone https://github.com/parmigggiana/xai /content/xai\n",
    "        %cd /content/xai\n",
    "        !git fetch\n",
    "        !git reset --hard origin/main\n",
    "        %pip install -r requirements.txt\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector\n",
    "from src.utils import download_and_extract_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MMWHS\"]\n",
    "domains = [\"MR\", \"CT\"]\n",
    "data_path = \"data/\"\n",
    "checkpoint_path = \"checkpoints/\"\n",
    "outputs_path = \"outputs/\"\n",
    "use_3d = True\n",
    "training_epochs = {\n",
    "    (\"CHAOS\", \"MR\"): 30,\n",
    "    (\"CHAOS\", \"CT\"): 10,\n",
    "    (\"MMWHS\", \"MR\"): 30,\n",
    "    (\"MMWHS\", \"CT\"): 20,\n",
    "}\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "data_path = Path(data_path)\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai import transforms\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = outputs_path / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "\n",
    "def get_preprocessing(domain, is_training=True):\n",
    "    \"\"\"\n",
    "    Get comprehensive preprocessing pipeline for volumetric medical data.\n",
    "\n",
    "    Args:\n",
    "        domain: 'MR' or 'CT'\n",
    "        is_training: Whether this is for training (includes augmentations)\n",
    "    \"\"\"\n",
    "    if use_3d:\n",
    "        # Base preprocessing steps (applied to all data)\n",
    "        base_transforms = [\n",
    "            transforms.Orientation(axcodes=\"RAS\"),  # Standardize spatial orientation (D, H, W)\n",
    "            transforms.Spacing(pixdim=(1.5, 1.5, 2.0), mode=\"trilinear\"),  # Consistent voxel spacing\n",
    "        ]\n",
    "\n",
    "        # Domain-specific intensity normalization\n",
    "        if domain.upper() in ['CT']:\n",
    "            # CT: Clip HU values and normalize\n",
    "            base_transforms.extend([\n",
    "                transforms.ScaleIntensityRange(\n",
    "                    a_min=-200, a_max=300, b_min=0.0, b_max=1.0, clip=True\n",
    "                ),\n",
    "            ])\n",
    "        else:  # MR/MRI\n",
    "            # MR: Z-score normalization (handles varying intensity ranges)\n",
    "            base_transforms.extend([\n",
    "                transforms.NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "            ])\n",
    "\n",
    "        # Spatial resizing\n",
    "        base_transforms.append(\n",
    "            transforms.Resize(spatial_size=96, size_mode=\"longest\", mode=\"trilinear\")\n",
    "        )\n",
    "\n",
    "        # Training augmentations\n",
    "        if is_training:\n",
    "            augmentation_transforms = [\n",
    "                transforms.RandRotate90(prob=0.3, spatial_axes=(0, 1)),\n",
    "                transforms.RandFlip(prob=0.3, spatial_axis=0),\n",
    "                transforms.RandAffine(\n",
    "                    prob=0.3,\n",
    "                    rotate_range=0.1,\n",
    "                    translate_range=5,\n",
    "                    scale_range=0.1,\n",
    "                    mode=\"trilinear\"\n",
    "                ),\n",
    "                transforms.RandGaussianNoise(prob=0.2, std=0.05),\n",
    "                transforms.RandAdjustContrast(prob=0.2, gamma=(0.9, 1.1)),\n",
    "            ]\n",
    "            base_transforms.extend(augmentation_transforms)\n",
    "\n",
    "        # Final conversion to tensor\n",
    "        base_transforms.extend([\n",
    "            # transforms.EnsureChannelFirst(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.EnsureType(dtype=torch.float32),\n",
    "        ])\n",
    "\n",
    "        return transforms.Compose(base_transforms)\n",
    "    else:\n",
    "        # 2D preprocessing (if needed)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning loop\n",
    "\n",
    "for (dataset_name, domain), epochs in training_epochs.items():\n",
    "    download_and_extract_dataset(dataset_name, data_path)\n",
    "    preprocess = get_preprocessing(domain, is_training=True)\n",
    "\n",
    "    filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "    filename = checkpoint_path / filename\n",
    "    # Check if the finetuned checkpoint already exists\n",
    "    if filename.exists():\n",
    "        print(\n",
    "            f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    print(\n",
    "        f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images \"\n",
    "    )\n",
    "    dataset: BaseDataset = get_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        domain=domain,\n",
    "        preprocess=preprocess,\n",
    "        base_path=data_path,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        slice_2d=not use_3d,\n",
    "    )\n",
    "\n",
    "    model = dataset.get_model(\n",
    "        encoder_type=\"swin_unetr\",\n",
    "    )\n",
    "\n",
    "    # Save the baseline model's state_dict before finetuning\n",
    "    baseline_filename = (\n",
    "        checkpoint_path\n",
    "        / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "    )\n",
    "    torch.save(model.encoder, baseline_filename)\n",
    "    print(\n",
    "        f\"Processing {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images\"\n",
    "    )\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline\",\n",
    "        model_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the segmentation head\n",
    "    # For the proposal of the paper this part should not be done like this!\n",
    "    # This requires data - the original task arithmetic paper builds classification heads using no data, only templates\n",
    "    # if we have time this point should be addressed, otherwise at least mention that the technical problem\n",
    "    # requires more developement time and the proof of concept should still be somewhat solid.\n",
    "    model.freeze_body()\n",
    "    model.finetune(epochs=epochs, learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    # Save the head\n",
    "    torch.save(model.head, checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_head.pth\")\n",
    "\n",
    "    metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_head\",\n",
    "        metrics,\n",
    "    )\n",
    "\n",
    "    # Finetune the encoder-decoder\n",
    "    model.unfreeze()\n",
    "    model.freeze_head()\n",
    "    history = model.finetune(\n",
    "        epochs=epochs,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "    # Save the finetuned model's state_dict\n",
    "\n",
    "    torch.save(model.encoder, filename)\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned\",\n",
    "        model_metrics,\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1df630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.networks.nets.swin_unetr import SwinTransformer\n",
    "from monai.networks.blocks.patchembedding import PatchEmbed\n",
    "from torch.nn.modules.conv import Conv3d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.container import ModuleList\n",
    "from monai.networks.nets.swin_unetr import BasicLayer\n",
    "from monai.networks.nets.swin_unetr import SwinTransformerBlock\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "from monai.networks.nets.swin_unetr import WindowAttention\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch.nn.modules.activation import Softmax\n",
    "from torch.nn.modules.linear import Identity\n",
    "from monai.networks.blocks.mlp import MLPBlock\n",
    "from torch.nn.modules.activation import GELU\n",
    "from monai.networks.nets.swin_unetr import PatchMerging\n",
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock\n",
    "from monai.networks.blocks.dynunet_block import UnetResBlock\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "from torch.nn.modules.activation import LeakyReLU\n",
    "from torch.nn.modules.instancenorm import InstanceNorm3d\n",
    "from monai.networks.blocks.unetr_block import UnetrUpBlock\n",
    "from torch.nn.modules.conv import ConvTranspose3d\n",
    "from monai.networks.blocks.dynunet_block import UnetOutBlock\n",
    "\n",
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(\n",
    "            f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\"\n",
    "        )\n",
    "        baseline_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        )\n",
    "        finetuned_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        )\n",
    "        with torch.serialization.safe_globals(\n",
    "            [\n",
    "                SwinUNETR,\n",
    "                SwinTransformer,\n",
    "                PatchEmbed,\n",
    "                Conv3d,\n",
    "                Dropout,\n",
    "                ModuleList,\n",
    "                BasicLayer,\n",
    "                SwinTransformerBlock,\n",
    "                LayerNorm,\n",
    "                WindowAttention,\n",
    "                Linear,\n",
    "                Softmax,\n",
    "                Identity,\n",
    "                MLPBlock,\n",
    "                GELU,\n",
    "                PatchMerging,\n",
    "                UnetrBasicBlock,\n",
    "                UnetResBlock,\n",
    "                Convolution,\n",
    "                LeakyReLU,\n",
    "                InstanceNorm3d,\n",
    "                UnetrUpBlock,\n",
    "                ConvTranspose3d,\n",
    "                UnetOutBlock,\n",
    "            ]\n",
    "        ):\n",
    "            task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "            # Remove keys associated with the .out layer from the task vector\n",
    "            out_layer_keys = [k for k in task_vector.keys() if \"out.\" in k]\n",
    "            for k in out_layer_keys:\n",
    "                del task_vector[k]\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build composite task vectors using arithmetic\n",
    "composite_task_vectors = {\n",
    "    \"MMWHS_CT\": task_vectors[\"MMWHS_MR\"] + task_vectors[\"CHAOS_CT\"] - task_vectors[\"CHAOS_MR\"],\n",
    "    \"MMWHS_MR\": task_vectors[\"MMWHS_CT\"] + task_vectors[\"CHAOS_MR\"] - task_vectors[\"CHAOS_CT\"],\n",
    "    \"CHAOS_CT\": task_vectors[\"CHAOS_MR\"] + task_vectors[\"MMWHS_CT\"] - task_vectors[\"MMWHS_MR\"],\n",
    "    \"CHAOS_MR\": task_vectors[\"CHAOS_CT\"] + task_vectors[\"MMWHS_MR\"] - task_vectors[\"MMWHS_CT\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Vector Cross-Domain Evaluation (merged version, with nested loops for all configs)\n",
    "print(\"\\n🔄 Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "preprocess = get_preprocessing(domain, is_training=False)\n",
    "for dataset_name in dataset_names:\n",
    "    for target_domain in domains:\n",
    "\n",
    "        # Only add extra_kwarg 'liver_only' for CHAOS dataset\n",
    "        extra_kwargs = {}\n",
    "        if dataset_name == \"CHAOS\":\n",
    "            extra_kwargs[\"liver_only\"] = True\n",
    "\n",
    "        try:\n",
    "            composite_key = f\"{dataset_name}_{target_domain}\"\n",
    "            if composite_key not in composite_task_vectors:\n",
    "                # If the composite task vector does not exist, skip this iteration\n",
    "                print(\n",
    "                    f\"   ❗ Warning: Composite task vector for {composite_key} does not exist. Skipping evaluation.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"\\n{dataset_name}: {target_domain} adaptation\"\n",
    "            )\n",
    "            # Load target domain dataset\n",
    "            dataset_kwargs = dict(\n",
    "                dataset_name=dataset_name,\n",
    "                domain=target_domain,\n",
    "                base_path=data_path,\n",
    "                preprocess=preprocess,\n",
    "                batch_size=1,\n",
    "                num_workers=1,\n",
    "                slice_2d=False,\n",
    "            )\n",
    "            dataset_kwargs.update(extra_kwargs)\n",
    "            target_dataset = get_dataset(**dataset_kwargs)\n",
    "            target_model = target_dataset.get_model(encoder_type=\"swin_unetr\")\n",
    "\n",
    "            # Apply composite task vector for target domain\n",
    "            composite_task_vector = composite_task_vectors[composite_key]\n",
    "            target_model.load_task_vector(composite_task_vector)\n",
    "\n",
    "            # Overwrite the model's head with the saved one from the same task\n",
    "            head_filename = checkpoint_path / f\"{dataset_name}_{target_domain}_{'3d' if use_3d else '2d'}_head.pth\"\n",
    "            if head_filename.exists():\n",
    "                with torch.serialization.safe_globals([UnetOutBlock, Convolution, Conv3d]):\n",
    "                    target_model.head.load_state_dict(torch.load(head_filename, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\").state_dict())\n",
    "            else:\n",
    "                print(\n",
    "                    f\"   ❗ Warning: Head file {head_filename} does not exist. Skipping evaluation.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Evaluate cross-domain performance\n",
    "            metrics = target_model.evaluate()\n",
    "            update_metrics(f\"{composite_key}_adaptation\", metrics)\n",
    "\n",
    "            print(\n",
    "                f\"   ✅ {dataset_name} {target_domain}: Dice={metrics.get('dice', 0):.3f}, Hausdorff={metrics.get('hausdorff', 0):.3f}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"   ❌ {dataset_name} {target_domain}\") from  e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display all metrics\n",
    "metrics_file = outputs_path / \"metrics.json\"\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, \"r\") as f:\n",
    "        all_metrics = json.load(f)\n",
    "\n",
    "    print(\"\\n📊 COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline performance\n",
    "    print(\"\\n🏁 Baseline Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"baseline\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # After Head-training performance\n",
    "    print(\"\\n🏋️‍♂️ After Head-Training Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"head\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Finetuned performance\n",
    "    print(\"\\n🏆 Finetuned Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"finetuned\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Cross-domain adaptation results\n",
    "    print(\"\\n🔄 Cross-Domain Adaptation Results:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"adaptation\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "else:\n",
    "    print(\"No metrics file found. Run the experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import shutil\n",
    "\n",
    "\n",
    "    # Copy checkpoints.zip to Google Drive\n",
    "    !zip -r /content/checkpoints.zip /content/xai/checkpoints\n",
    "    shutil.copy('/content/checkpoints.zip', '/content/drive/MyDrive/xai/checkpoints.zip')\n",
    "\n",
    "    # Copy metrics.json to Google Drive\n",
    "    shutil.copy('/content/xai/outputs/metrics.json', '/content/drive/MyDrive/xai/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE:\n",
    "    !zip -r /kaggle/working/checkpoints.zip /kaggle/working/xai/checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
