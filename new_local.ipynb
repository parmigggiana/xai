{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193624be",
   "metadata": {},
   "source": [
    "# Medical Image Preprocessing Pipeline Explanation\n",
    "\n",
    "This notebook implements comprehensive preprocessing for volumetric medical imaging data. Below are detailed explanations of each preprocessing step and why they're crucial for medical AI applications.\n",
    "\n",
    "## üìã Core Preprocessing Steps\n",
    "\n",
    "### 1. **EnsureChannelFirst()**\n",
    "- **Purpose**: Standardizes tensor format to (C, H, W, D) where C=channels\n",
    "- **Why Important**: Medical images can come in different formats. This ensures consistency for neural networks\n",
    "- **Example**: Converts (H, W, D) ‚Üí (1, H, W, D) for single-channel data\n",
    "\n",
    "### 2. **Orientation(axcodes=\"RAS\")**\n",
    "- **Purpose**: Standardizes anatomical orientation to Right-Anterior-Superior\n",
    "- **Why Critical**: Medical scans can have different orientations (RAS, LPS, etc.)\n",
    "- **Impact**: Ensures consistent spatial relationships across all data\n",
    "- **Alternative**: LPS (Left-Posterior-Superior) is also common\n",
    "\n",
    "### 3. **Spacing(pixdim=(1.5, 1.5, 2.0))**\n",
    "- **Purpose**: Resamples voxels to consistent physical dimensions\n",
    "- **Why Essential**: Different scanners produce different voxel sizes (e.g., 0.5mm vs 2mm)\n",
    "- **Parameters**: \n",
    "  - `pixdim`: Target spacing in mm (x, y, z)\n",
    "  - `mode`: Interpolation method (\"bilinear\" for images, \"nearest\" for labels)\n",
    "- **Impact**: Ensures fair comparison and consistent model input\n",
    "\n",
    "## üè• Domain-Specific Intensity Normalization\n",
    "\n",
    "### For CT Scans: ScaleIntensityRange()\n",
    "```python\n",
    "ScaleIntensityRange(a_min=-200, a_max=300, b_min=0.0, b_max=1.0, clip=True)\n",
    "```\n",
    "- **Purpose**: Normalizes Hounsfield Units (HU) to [0,1] range\n",
    "- **HU Values**:\n",
    "  - Air: -1000 HU\n",
    "  - Water: 0 HU  \n",
    "  - Bone: +1000 HU\n",
    "  - Soft tissue: -200 to +300 HU\n",
    "- **Why Clipping**: Removes extreme outliers that could skew normalization\n",
    "\n",
    "### For MRI Scans: NormalizeIntensity()\n",
    "```python\n",
    "NormalizeIntensity(nonzero=True, channel_wise=True)\n",
    "```\n",
    "- **Purpose**: Z-score normalization (mean=0, std=1)\n",
    "- **Why Different from CT**: MRI intensities are relative, not absolute like CT\n",
    "- **Parameters**:\n",
    "  - `nonzero=True`: Only normalizes non-zero voxels (ignores background)\n",
    "  - `channel_wise=True`: Normalizes each channel independently\n",
    "\n",
    "### 4. **Resize(spatial_size=(96, 96, 96))**\n",
    "- **Purpose**: Standardizes volume dimensions for batch processing\n",
    "- **Why Necessary**: Medical volumes vary greatly in size\n",
    "- **Trade-offs**: \n",
    "  - Smaller size = faster training, less memory\n",
    "  - Larger size = more detail, better performance\n",
    "- **Mode**: \"trilinear\" for smooth interpolation\n",
    "\n",
    "## üîÑ Data Augmentation (Training Only)\n",
    "\n",
    "### Spatial Augmentations\n",
    "\n",
    "#### RandRotate90(prob=0.3, spatial_axes=(0, 1))\n",
    "- **Purpose**: Random 90¬∞ rotations in axial plane\n",
    "- **Why Conservative**: Medical anatomy has consistent orientation\n",
    "- **Probability**: 30% to avoid over-augmentation\n",
    "\n",
    "#### RandFlip(prob=0.3, spatial_axis=0)\n",
    "- **Purpose**: Random horizontal flips\n",
    "- **Anatomical Consideration**: Only flips that preserve medical validity\n",
    "- **Limitation**: Careful with asymmetric organs (heart, liver)\n",
    "\n",
    "#### RandAffine()\n",
    "```python\n",
    "RandAffine(prob=0.3, rotate_range=0.1, translate_range=5, scale_range=0.1)\n",
    "```\n",
    "- **Purpose**: Small geometric transformations\n",
    "- **Parameters**:\n",
    "  - `rotate_range=0.1`: ¬±5.7¬∞ rotation\n",
    "  - `translate_range=5`: ¬±5 voxel shifts\n",
    "  - `scale_range=0.1`: ¬±10% scaling\n",
    "- **Why Small Values**: Medical images require precise alignment\n",
    "\n",
    "### Intensity Augmentations\n",
    "\n",
    "#### RandGaussianNoise(prob=0.2, std=0.05)\n",
    "- **Purpose**: Simulates scanner noise variations\n",
    "- **Why Important**: Different scanners have different noise characteristics\n",
    "- **Conservative std**: 5% noise to avoid corrupting anatomical features\n",
    "\n",
    "#### RandAdjustContrast(prob=0.2, gamma=(0.9, 1.1))\n",
    "- **Purpose**: Simulates different contrast settings\n",
    "- **Gamma Range**: 10% variation is subtle but effective\n",
    "- **Medical Relevance**: Accounts for different scanning protocols\n",
    "\n",
    "## üîß Final Processing Steps\n",
    "\n",
    "### ToTensor() & EnsureType(dtype=torch.float32)\n",
    "- **Purpose**: Converts to PyTorch tensors with consistent data type\n",
    "- **Why float32**: Balance between precision and memory usage\n",
    "- **GPU Compatibility**: Ensures tensor can be moved to GPU efficiently\n",
    "\n",
    "## üéØ Key Design Principles\n",
    "\n",
    "### 1. **Domain Awareness**\n",
    "- Different modalities (CT vs MRI) require different intensity handling\n",
    "- Anatomical constraints guide augmentation choices\n",
    "\n",
    "### 2. **Conservative Augmentation**\n",
    "- Medical images require anatomical validity\n",
    "- Small, realistic transformations preserve diagnostic quality\n",
    "\n",
    "### 3. **Consistency First**\n",
    "- Standardized spacing, orientation, and intensity ranges\n",
    "- Enables fair comparison across different scanners and protocols\n",
    "\n",
    "### 4. **Training vs Validation**\n",
    "- Augmentations only during training\n",
    "- Deterministic preprocessing for validation/testing\n",
    "\n",
    "## ‚ö†Ô∏è Important Considerations\n",
    "\n",
    "### Memory Management\n",
    "- Volumetric data is memory-intensive\n",
    "- Consider patch-based processing for very large volumes\n",
    "\n",
    "### Quality Control\n",
    "- Always validate preprocessing results visually\n",
    "- Check for anatomical correctness after transformations\n",
    "\n",
    "### Dataset-Specific Tuning\n",
    "- HU ranges might need adjustment for different CT protocols\n",
    "- MRI sequences may require specialized normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bb3b4",
   "metadata": {},
   "source": [
    "In Kaggle, add the following to the dependencies:\n",
    "```\n",
    "pip install torch\n",
    "pip install torchvision\n",
    "pip install numpy\n",
    "pip install pydicom\n",
    "pip install PILlow\n",
    "pip install matplotlib\n",
    "```\n",
    "Enable file persistence and internet access.\n",
    "Remember that you can run the whole notebook and close the runtime without wasting resources by going to File > Save Version > Save & Run All (Double check that GPU is selected in the advanced settings).\n",
    "Later, by going to 'File' > 'Version history' you can view the full logs and download the output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c8f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Kaggle\n",
    "import os\n",
    "\n",
    "IN_KAGGLE = False\n",
    "if os.environ.get(\"KAGGLE_URL_BASE\", \"\"):\n",
    "    IN_KAGGLE = True\n",
    "    !git clone https://github.com/parmigggiana/xai /kaggle/working/xai\n",
    "    %cd xai\n",
    "    !git fetch\n",
    "    !git reset --hard origin/main\n",
    "    %pip install 'napari[pyqt6,optional]==0.6.2a1' 'monai[einops,nibabel]>=1.1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c6af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if running in Google Colab\n",
    "IN_COLAB = False\n",
    "if not IN_KAGGLE:\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import drive\n",
    "        IN_COLAB = True\n",
    "        import os\n",
    "        drive.mount('/content/drive')\n",
    "        os.makedirs('/content/drive/MyDrive/xai', exist_ok=True)\n",
    "        !git clone https://github.com/parmigggiana/xai /content/xai\n",
    "        %cd /content/xai\n",
    "        !git fetch\n",
    "        !git reset --hard origin/main\n",
    "        %pip install -r requirements.txt\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dc085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.registry import get_dataset\n",
    "from src.datasets.common import BaseDataset\n",
    "from pathlib import Path\n",
    "import json\n",
    "from src.task_vector import TaskVector\n",
    "from src.utils import download_and_extract_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea7935",
   "metadata": {},
   "source": [
    "## üîç Practical Example: Before vs After Preprocessing\n",
    "\n",
    "Here's what happens to your medical image data through each step:\n",
    "\n",
    "### Original Data Issues:\n",
    "```\n",
    "CT Scan A: Shape=(512, 512, 200), Spacing=(0.5, 0.5, 1.0)mm, HU=[-1024, 3071]\n",
    "CT Scan B: Shape=(256, 256, 150), Spacing=(1.0, 1.0, 2.0)mm, HU=[-500, 2000]\n",
    "MRI Scan A: Shape=(320, 320, 180), Spacing=(0.8, 0.8, 1.5)mm, Intensity=[0, 4095]\n",
    "MRI Scan B: Shape=(384, 384, 160), Spacing=(0.6, 0.6, 1.2)mm, Intensity=[0, 2048]\n",
    "```\n",
    "\n",
    "### After Preprocessing Pipeline:\n",
    "```\n",
    "All Scans: Shape=(96, 96, 96), Spacing=(1.5, 1.5, 2.0)mm, Values=[0.0, 1.0]\n",
    "```\n",
    "\n",
    "### Step-by-Step Transformation:\n",
    "\n",
    "1. **EnsureChannelFirst**: (H,W,D) ‚Üí (1,H,W,D)\n",
    "2. **Orientation**: All aligned to RAS coordinate system\n",
    "3. **Spacing**: Resampled to consistent 1.5√ó1.5√ó2.0mm voxels\n",
    "4. **Intensity**: \n",
    "   - CT: HU [-200,300] ‚Üí [0,1]\n",
    "   - MRI: Z-score normalized ‚Üí mean‚âà0, std‚âà1\n",
    "5. **Resize**: All volumes ‚Üí 96¬≥ voxels\n",
    "6. **Augmentation**: Random but anatomically valid transformations\n",
    "\n",
    "This ensures your model sees consistent, comparable data regardless of the original scanner or protocol!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cba54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"CHAOS\", \"MMWHS\"]\n",
    "domains = [\"MR\", \"CT\"]\n",
    "data_path = \"data/\"\n",
    "checkpoint_path = \"checkpoints/\"\n",
    "outputs_path = \"outputs/\"\n",
    "use_3d = True\n",
    "training_epochs = {\n",
    "    (\"CHAOS\", \"MR\"): 30,\n",
    "    (\"CHAOS\", \"CT\"): 10,\n",
    "    (\"MMWHS\", \"MR\"): 30,\n",
    "    (\"MMWHS\", \"CT\"): 20,\n",
    "}\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0801709",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = Path(checkpoint_path)\n",
    "outputs_path = Path(outputs_path)\n",
    "data_path = Path(data_path)\n",
    "checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "outputs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb09eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai import transforms\n",
    "\n",
    "def update_metrics(name, new_metrics):\n",
    "    metrics_file = outputs_path / \"metrics.json\"\n",
    "\n",
    "    if not metrics_file.exists():\n",
    "        metrics = {}\n",
    "    else:\n",
    "        with open(metrics_file, \"r\") as f:\n",
    "            metrics = json.load(f)\n",
    "\n",
    "    metrics[name] = new_metrics\n",
    "    with open(metrics_file, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "\n",
    "def get_preprocessing(domain, is_training=True):\n",
    "    \"\"\"\n",
    "    Get comprehensive preprocessing pipeline for volumetric medical data.\n",
    "\n",
    "    Args:\n",
    "        domain: 'MR' or 'CT'\n",
    "        is_training: Whether this is for training (includes augmentations)\n",
    "    \"\"\"\n",
    "    if use_3d:\n",
    "        # Base preprocessing steps (applied to all data)\n",
    "        base_transforms = [\n",
    "            transforms.EnsureChannelFirst(),\n",
    "            transforms.Orientation(axcodes=\"RAS\"),  # Standardize orientation\n",
    "            transforms.Spacing(pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),  # Consistent voxel spacing\n",
    "        ]\n",
    "\n",
    "        # Domain-specific intensity normalization\n",
    "        if domain.upper() in ['CT']:\n",
    "            # CT: Clip HU values and normalize\n",
    "            base_transforms.extend([\n",
    "                transforms.ScaleIntensityRange(\n",
    "                    a_min=-200, a_max=300, b_min=0.0, b_max=1.0, clip=True\n",
    "                ),\n",
    "            ])\n",
    "        else:  # MR/MRI\n",
    "            # MR: Z-score normalization (handles varying intensity ranges)\n",
    "            base_transforms.extend([\n",
    "                transforms.NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "            ])\n",
    "\n",
    "        # Spatial resizing\n",
    "        base_transforms.append(\n",
    "            transforms.Resize(spatial_size=(96, 96, 96), mode=\"trilinear\")\n",
    "        )\n",
    "\n",
    "        # Training augmentations\n",
    "        if is_training:\n",
    "            augmentation_transforms = [\n",
    "                transforms.RandRotate90(prob=0.3, spatial_axes=(0, 1)),\n",
    "                transforms.RandFlip(prob=0.3, spatial_axis=0),\n",
    "                transforms.RandAffine(\n",
    "                    prob=0.3,\n",
    "                    rotate_range=0.1,\n",
    "                    translate_range=5,\n",
    "                    scale_range=0.1,\n",
    "                    mode=(\"bilinear\", \"nearest\")\n",
    "                ),\n",
    "                transforms.RandGaussianNoise(prob=0.2, std=0.05),\n",
    "                transforms.RandAdjustContrast(prob=0.2, gamma=(0.9, 1.1)),\n",
    "            ]\n",
    "            base_transforms.extend(augmentation_transforms)\n",
    "\n",
    "        # Final conversion to tensor\n",
    "        base_transforms.extend([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.EnsureType(dtype=torch.float32),\n",
    "        ])\n",
    "\n",
    "        return transforms.Compose(base_transforms)\n",
    "    else:\n",
    "        # 2D preprocessing (if needed)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned model for CHAOS in MR domain with 3d images already exists at checkpoints/CHAOS_MR_3d_finetuned.pth. Skipping finetuning.\n",
      "Finetuned model for CHAOS in CT domain with 3d images already exists at checkpoints/CHAOS_CT_3d_finetuned.pth. Skipping finetuning.\n",
      "Finetuned model for MMWHS in MR domain with 3d images already exists at checkpoints/MMWHS_MR_3d_finetuned.pth. Skipping finetuning.\n",
      "Finetuned model for MMWHS in CT domain with 3d images already exists at checkpoints/MMWHS_CT_3d_finetuned.pth. Skipping finetuning.\n"
     ]
    }
   ],
   "source": [
    "# Finetuning loop\n",
    "\n",
    "for (dataset_name, domain), epochs in training_epochs.items():\n",
    "    download_and_extract_dataset(dataset_name, data_path)\n",
    "    preprocess = get_preprocessing(domain, is_training=True)\n",
    "\n",
    "    filename = f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "    filename = checkpoint_path / filename\n",
    "    # Check if the finetuned checkpoint already exists\n",
    "    if filename.exists():\n",
    "        print(\n",
    "            f\"Finetuned model for {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images already exists at {filename}. Skipping finetuning.\"\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    print(\n",
    "        f\"Finetuning on {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images \"\n",
    "    )\n",
    "    dataset: BaseDataset = get_dataset(\n",
    "        dataset_name=dataset_name,\n",
    "        domain=domain,\n",
    "        preprocess=preprocess,\n",
    "        base_path=data_path,\n",
    "        batch_size=1,\n",
    "        num_workers=1,\n",
    "        slice_2d=not use_3d,\n",
    "    )\n",
    "\n",
    "    model = dataset.get_model(\n",
    "        encoder_type=\"swin_unetr\",\n",
    "    )\n",
    "\n",
    "    # Save the baseline model's state_dict before finetuning\n",
    "    baseline_filename = (\n",
    "        checkpoint_path\n",
    "        / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "    )\n",
    "    torch.save(model.encoder, baseline_filename)\n",
    "    print(\n",
    "        f\"Processing {dataset_name} in {domain} domain with {'3d' if use_3d else '2d'} images\"\n",
    "    )\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline\",\n",
    "        model_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the segmentation head\n",
    "    # For the proposal of the paper this part should not be done like this!\n",
    "    # This requires data - the original task arithmetic paper builds classification heads using no data, only templates\n",
    "    # if we have time this point should be addressed, otherwise at least mention that the technical problem\n",
    "    # requires more developement time and the proof of concept should still be somewhat solid.\n",
    "    model.freeze_body()\n",
    "    model.finetune(epochs=epochs, learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    # Save the head\n",
    "    torch.save(model.head, checkpoint_path / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_head.pth\")\n",
    "\n",
    "    metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_head\",\n",
    "        metrics,\n",
    "    )\n",
    "\n",
    "    # Finetune the encoder-decoder\n",
    "    model.unfreeze()\n",
    "    model.freeze_head()\n",
    "    history = model.finetune(\n",
    "        epochs=epochs,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "    # Save the finetuned model's state_dict\n",
    "\n",
    "    torch.save(model.encoder, filename)\n",
    "    model_metrics = model.evaluate()\n",
    "    update_metrics(\n",
    "        f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned\",\n",
    "        model_metrics,\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090233",
   "metadata": {},
   "source": [
    "# Domain adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1df630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building task vector for CHAOS dataset in MR domain with 3d images\n",
      "Building task vector for CHAOS dataset in CT domain with 3d images\n",
      "Building task vector for MMWHS dataset in MR domain with 3d images\n",
      "Building task vector for MMWHS dataset in CT domain with 3d images\n"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.networks.nets.swin_unetr import SwinTransformer\n",
    "from monai.networks.blocks.patchembedding import PatchEmbed\n",
    "from torch.nn.modules.conv import Conv3d\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.container import ModuleList\n",
    "from monai.networks.nets.swin_unetr import BasicLayer\n",
    "from monai.networks.nets.swin_unetr import SwinTransformerBlock\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "from monai.networks.nets.swin_unetr import WindowAttention\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch.nn.modules.activation import Softmax\n",
    "from torch.nn.modules.linear import Identity\n",
    "from monai.networks.blocks.mlp import MLPBlock\n",
    "from torch.nn.modules.activation import GELU\n",
    "from monai.networks.nets.swin_unetr import PatchMerging\n",
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock\n",
    "from monai.networks.blocks.dynunet_block import UnetResBlock\n",
    "from monai.networks.blocks.convolutions import Convolution\n",
    "from torch.nn.modules.activation import LeakyReLU\n",
    "from torch.nn.modules.instancenorm import InstanceNorm3d\n",
    "from monai.networks.blocks.unetr_block import UnetrUpBlock\n",
    "from torch.nn.modules.conv import ConvTranspose3d\n",
    "from monai.networks.blocks.dynunet_block import UnetOutBlock\n",
    "\n",
    "# Build Task Vectors for each dataset and domain\n",
    "task_vectors = {}\n",
    "for dataset_name in dataset_names:\n",
    "    for domain in domains:\n",
    "        print(\n",
    "            f\"Building task vector for {dataset_name} dataset in {domain} domain with {'3d' if use_3d else '2d'} images\"\n",
    "        )\n",
    "        baseline_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_baseline.pth\"\n",
    "        )\n",
    "        finetuned_checkpoint = (\n",
    "            checkpoint_path\n",
    "            / f\"{dataset_name}_{domain}_{'3d' if use_3d else '2d'}_finetuned.pth\"\n",
    "        )\n",
    "        with torch.serialization.safe_globals(\n",
    "            [\n",
    "                SwinUNETR,\n",
    "                SwinTransformer,\n",
    "                PatchEmbed,\n",
    "                Conv3d,\n",
    "                Dropout,\n",
    "                ModuleList,\n",
    "                BasicLayer,\n",
    "                SwinTransformerBlock,\n",
    "                LayerNorm,\n",
    "                WindowAttention,\n",
    "                Linear,\n",
    "                Softmax,\n",
    "                Identity,\n",
    "                MLPBlock,\n",
    "                GELU,\n",
    "                PatchMerging,\n",
    "                UnetrBasicBlock,\n",
    "                UnetResBlock,\n",
    "                Convolution,\n",
    "                LeakyReLU,\n",
    "                InstanceNorm3d,\n",
    "                UnetrUpBlock,\n",
    "                ConvTranspose3d,\n",
    "                UnetOutBlock,\n",
    "            ]\n",
    "        ):\n",
    "            task_vector = TaskVector(baseline_checkpoint, finetuned_checkpoint)\n",
    "            # Remove keys associated with the .out layer from the task vector\n",
    "            out_layer_keys = [k for k in task_vector.keys() if \"out.\" in k]\n",
    "            for k in out_layer_keys:\n",
    "                del task_vector[k]\n",
    "        task_vectors[f\"{dataset_name}_{domain}\"] = task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb6d5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build composite task vectors using arithmetic\n",
    "composite_task_vectors = {\n",
    "    \"MMWHS_CT\": task_vectors[\"MMWHS_MR\"] + task_vectors[\"CHAOS_CT\"] - task_vectors[\"CHAOS_MR\"],\n",
    "    \"MMWHS_MR\": task_vectors[\"MMWHS_CT\"] + task_vectors[\"CHAOS_MR\"] - task_vectors[\"CHAOS_CT\"],\n",
    "    \"CHAOS_CT\": task_vectors[\"CHAOS_MR\"] + task_vectors[\"MMWHS_CT\"] - task_vectors[\"MMWHS_MR\"],\n",
    "    \"CHAOS_MR\": task_vectors[\"CHAOS_CT\"] + task_vectors[\"MMWHS_MR\"] - task_vectors[\"MMWHS_CT\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ea1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Task Vector Cross-Domain Adaptation Experiments\n",
      "================================================================================\n",
      "\n",
      "CHAOS: MR adaptation\n",
      "2025-07-27 17:26:43,305 - INFO - Expected md5 is None, skip md5 check for file data/ssl_pretrained_weights.pth.\n",
      "2025-07-27 17:26:43,306 - INFO - File exists: data/ssl_pretrained_weights.pth, skipped downloading.\n",
      "Total updated layers 159 / 159\n",
      "Pretrained Weights Succesfully Loaded !\n",
      "‚ö†Ô∏è Task vector missing key: out.conv.conv.weight, skipping update.\n",
      "‚ö†Ô∏è Task vector missing key: out.conv.conv.bias, skipping update.\n",
      "üîç Evaluating train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Task Vector Cross-Domain Evaluation (merged version, with nested loops for all configs)\n",
    "print(\"\\nüîÑ Task Vector Cross-Domain Adaptation Experiments\")\n",
    "print(\"=\" * 80)\n",
    "preprocess = get_preprocessing(domain, is_training=False)\n",
    "for dataset_name in dataset_names:\n",
    "    for target_domain in domains:\n",
    "\n",
    "        # Only add extra_kwarg 'liver_only' for CHAOS dataset\n",
    "        extra_kwargs = {}\n",
    "        if dataset_name == \"CHAOS\":\n",
    "            extra_kwargs[\"liver_only\"] = True\n",
    "\n",
    "        try:\n",
    "            composite_key = f\"{dataset_name}_{target_domain}\"\n",
    "            if composite_key not in composite_task_vectors:\n",
    "                # If the composite task vector does not exist, skip this iteration\n",
    "                print(\n",
    "                    f\"   ‚ùó Warning: Composite task vector for {composite_key} does not exist. Skipping evaluation.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            print(\n",
    "                f\"\\n{dataset_name}: {target_domain} adaptation\"\n",
    "            )\n",
    "            # Load target domain dataset\n",
    "            dataset_kwargs = dict(\n",
    "                dataset_name=dataset_name,\n",
    "                domain=target_domain,\n",
    "                base_path=data_path,\n",
    "                preprocess=preprocess,\n",
    "                batch_size=1,\n",
    "                num_workers=1,\n",
    "                slice_2d=False,\n",
    "            )\n",
    "            dataset_kwargs.update(extra_kwargs)\n",
    "            target_dataset = get_dataset(**dataset_kwargs)\n",
    "            target_model = target_dataset.get_model(encoder_type=\"swin_unetr\")\n",
    "\n",
    "            # Apply composite task vector for target domain\n",
    "            composite_task_vector = composite_task_vectors[composite_key]\n",
    "            target_model.load_task_vector(composite_task_vector)\n",
    "\n",
    "            # Overwrite the model's head with the saved one from the same task\n",
    "            head_filename = checkpoint_path / f\"{dataset_name}_{target_domain}_{'3d' if use_3d else '2d'}_head.pth\"\n",
    "            if head_filename.exists():\n",
    "                with torch.serialization.safe_globals([UnetOutBlock, Convolution, Conv3d]):\n",
    "                    target_model.head.load_state_dict(torch.load(head_filename, map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\").state_dict())\n",
    "            else:\n",
    "                print(\n",
    "                    f\"   ‚ùó Warning: Head file {head_filename} does not exist. Skipping evaluation.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            # Evaluate cross-domain performance\n",
    "            metrics = target_model.evaluate()\n",
    "            update_metrics(f\"{composite_key}_adaptation\", metrics)\n",
    "\n",
    "            print(\n",
    "                f\"   ‚úÖ {dataset_name} {target_domain}: Dice={metrics.get('dice', 0):.3f}, Hausdorff={metrics.get('hausdorff', 0):.3f}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"   ‚ùå {dataset_name} {target_domain} error: {e}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display all metrics\n",
    "metrics_file = outputs_path / \"metrics.json\"\n",
    "if metrics_file.exists():\n",
    "    with open(metrics_file, \"r\") as f:\n",
    "        all_metrics = json.load(f)\n",
    "\n",
    "    print(\"\\nüìä COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Baseline performance\n",
    "    print(\"\\nüèÅ Baseline Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"baseline\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # After Head-training performance\n",
    "    print(\"\\nüèãÔ∏è‚Äç‚ôÇÔ∏è After Head-Training Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"head\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Finetuned performance\n",
    "    print(\"\\nüèÜ Finetuned Performance:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"finetuned\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "\n",
    "    # Cross-domain adaptation results\n",
    "    print(\"\\nüîÑ Cross-Domain Adaptation Results:\")\n",
    "    for key, metrics in all_metrics.items():\n",
    "        if \"adaptation\" in key:\n",
    "            dice = metrics.get(\"train\").get(\"dice\", 0)\n",
    "            hausdorff = metrics.get(\"train\").get(\"hausdorff\", 0)\n",
    "            print(f\"   {key}: Dice={dice:.3f}, HD={hausdorff:.3f}\")\n",
    "else:\n",
    "    print(\"No metrics file found. Run the experiments first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe0a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    import shutil\n",
    "\n",
    "\n",
    "    # Copy checkpoints.zip to Google Drive\n",
    "    !zip -r /content/checkpoints.zip /content/xai/checkpoints\n",
    "    shutil.copy('/content/checkpoints.zip', '/content/drive/MyDrive/xai/checkpoints.zip')\n",
    "\n",
    "    # Copy metrics.json to Google Drive\n",
    "    shutil.copy('/content/xai/outputs/metrics.json', '/content/drive/MyDrive/xai/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140d2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_KAGGLE:\n",
    "    !zip -r /kaggle/working/checkpoints.zip /kaggle/working/xai/checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
