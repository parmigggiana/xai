"""
Generated by GPT-4.1 converting modeling.py to segmentation
"""

import open_clip
import torch
import torch.nn.functional as F

from src import utils
from sklearn.metrics import jaccard_score
import numpy as np
from monai.inferers import sliding_window_inference
from monai.metrics import DiceMetric, HausdorffDistanceMetric


class ImageEncoder(torch.nn.Module):
    def __init__(self, model, keep_lang=False, cache_dir=None, openclip_cachedir=None):
        super().__init__()
        print(f"Loading {model} pre-trained weights.")
        if "__pretrained__" in model:
            name, pretrained = model.split("__pretrained__")
        else:
            name = model
            pretrained = "openai"
        self.model, self.train_preprocess, self.val_preprocess = (
            open_clip.create_model_and_transforms(
                name, pretrained=pretrained, cache_dir=openclip_cachedir
            )
        )
        self.cache_dir = cache_dir
        if not keep_lang and hasattr(self.model, "transformer"):
            delattr(self.model, "transformer")

    def forward(self, images):
        assert self.model is not None
        # For segmentation, we want feature maps, not pooled features
        if hasattr(self.model.visual, "forward_features"):
            features = self.model.visual.forward_features(images)
        else:
            features = self.model.encode_image(images)
        return features

    def __call__(self, inputs):
        return self.forward(inputs)

    def save(self, filename):
        print(f"Saving image encoder to {filename}")
        utils.torch_save(self, filename)

    @classmethod
    def load(cls, model_name, filename):
        print(f"Loading image encoder from {filename}")
        state_dict = torch.load(filename)
        return cls.load(model_name, state_dict)


class SegmentationHead(torch.nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        # Simple 1x1 conv for per-pixel classification
        self.conv = torch.nn.Conv2d(in_channels, num_classes, kernel_size=1)

    def forward(self, features):
        # features: (B, C, H, W)
        return self.conv(features)

    def __call__(self, features):
        return self.forward(features)

    def save(self, filename):
        print(f"Saving segmentation head to {filename}")
        utils.torch_save(self, filename)

    @classmethod
    def load(cls, filename):
        print(f"Loading segmentation head from {filename}")
        return utils.torch_load(filename)


class ImageSegmenter(torch.nn.Module):
    def __init__(self, image_encoder, segmentation_head, dataset=None):
        super().__init__()
        self.dataset = dataset
        self.image_encoder = image_encoder
        self.segmentation_head = segmentation_head
        if self.image_encoder is not None:
            self.train_preprocess = self.image_encoder.train_preprocess
            self.val_preprocess = self.image_encoder.val_preprocess

    def forward(self, inputs):
        features = self.image_encoder(inputs)
        # If features are not 4D, try to reshape or upsample as needed
        if features.dim() == 2:
            # (B, C) -> (B, C, 1, 1)
            features = features.unsqueeze(-1).unsqueeze(-1)
        outputs = self.segmentation_head(features)
        # Optionally upsample to input size
        if outputs.shape[-2:] != inputs.shape[-2:]:
            outputs = F.interpolate(
                outputs, size=inputs.shape[-2:], mode="bilinear", align_corners=False
            )
        return outputs

    def freeze_head(self):
        for param in self.segmentation_head.parameters():
            param.requires_grad = False

    def freeze(self):
        """
        Freeze the image encoder and segmentation head.
        """
        self.freeze_head()
        for param in self.image_encoder.parameters():
            param.requires_grad = False

    def __call__(self, inputs):
        return self.forward(inputs)

    def save(self, filename):
        print(f"Saving image segmenter to {filename}")
        utils.torch_save(self, filename)

    @classmethod
    def load(cls, filename):
        print(f"Loading image segmenter from {filename}")
        return utils.torch_load(filename)

    def evaluate(self):
        """
        Evaluate the segmenter on the dataset.
        """
        if self.dataset is None:
            raise ValueError("Dataset not provided for evaluation.")

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        self.eval()
        self.freeze()

        dice_metric = DiceMetric(include_background=False, reduction="mean")
        hausdorff_metric = HausdorffDistanceMetric(
            include_background=False, percentile=95
        )

        # Aggregate metrics
        dice_score = dice_metric.aggregate().item()
        hausdorff_dist = hausdorff_metric.aggregate().item()

        # Reset metrics for potential use
        dice_metric.reset()
        hausdorff_metric.reset()

        with torch.no_grad():
            for batch in self.dataset.train_loader:
                images = batch["image"].to(device)
                labels = batch["label"].to(device)

                outputs = sliding_window_inference(
                    inputs=images,
                    roi_size=(96, 96, 96),
                    sw_batch_size=1,
                    predictor=self,
                )

                # Apply argmax to get discrete segmentation
                preds = torch.argmax(outputs, dim=1, keepdim=True)

                # Compute metrics
                dice_metric(y_pred=preds, y=labels)
                hausdorff_metric(y_pred=preds, y=labels)

        train_dice_score = dice_metric.aggregate().item()
        train_hausdorff_dist = hausdorff_metric.aggregate().item()

        dice_metric.reset()
        hausdorff_metric.reset()

        with torch.no_grad():
            for batch in self.dataset.test_loader:
                images = batch["image"].to(device)
                labels = batch["label"].to(device)

                outputs = sliding_window_inference(
                    inputs=images,
                    roi_size=(96, 96, 96),
                    sw_batch_size=1,
                    predictor=self,
                )

                # Apply argmax to get discrete segmentation
                preds = torch.argmax(outputs, dim=1, keepdim=True)

                # Compute metrics
                dice_metric(y_pred=preds, y=labels)
                hausdorff_metric(y_pred=preds, y=labels)

        test_dice_score = dice_metric.aggregate().item()
        test_hausdorff_dist = hausdorff_metric.aggregate().item()

        # Reset metrics for potential use
        dice_metric.reset()
        hausdorff_metric.reset()

        return {
            "train_dice_score": train_dice_score,
            "train_hausdorff_dist": train_hausdorff_dist,
            "test_dice_score": test_dice_score,
            "test_hausdorff_dist": test_hausdorff_dist,
        }
